* 
* ==> Audit <==
* |------------|--------------------------------|----------|--------------------------------|---------|---------------------|---------------------|
|  Command   |              Args              | Profile  |              User              | Version |     Start Time      |      End Time       |
|------------|--------------------------------|----------|--------------------------------|---------|---------------------|---------------------|
| start      |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 10:54 +07 | 20 Mar 25 11:16 +07 |
|            |                                |          | Fadhilah                       |         |                     |                     |
| docker-env | minikube docker-env --shell    | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 12:24 +07 | 20 Mar 25 12:24 +07 |
|            | powershell                     |          | Fadhilah                       |         |                     |                     |
| image      | load sidecar-service:4.0       | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 12:26 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| image      | load book-service:4.0          | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 12:26 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:18 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:21 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:22 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| docker-env | minikube docker-env --shell    | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:24 +07 | 20 Mar 25 13:24 +07 |
|            | powershell                     |          | Fadhilah                       |         |                     |                     |
| image      | load sidecar-service:4.0       | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:27 +07 | 20 Mar 25 13:28 +07 |
|            |                                |          | Fadhilah                       |         |                     |                     |
| image      | load book-service:4.0          | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:30 +07 | 20 Mar 25 13:31 +07 |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:36 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      | --driver=docker                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:38 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      | --driver=hyperv                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:38 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| delete     |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:40 +07 | 20 Mar 25 13:40 +07 |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      | --driver=docker                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:40 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| delete     |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.35.0 | 20 Mar 25 13:45 +07 | 20 Mar 25 13:45 +07 |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.30.1 | 20 Mar 25 13:58 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      | --driver=docker                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.30.1 | 20 Mar 25 14:16 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| stop       |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.30.1 | 20 Mar 25 14:20 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| delete     |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.30.1 | 20 Mar 25 14:20 +07 | 20 Mar 25 14:20 +07 |
|            |                                |          | Fadhilah                       |         |                     |                     |
| start      |                                | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.30.1 | 20 Mar 25 14:23 +07 | 20 Mar 25 14:26 +07 |
|            |                                |          | Fadhilah                       |         |                     |                     |
| image      | load sidecar-service:4.0       | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.30.1 | 20 Mar 25 14:28 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| image      | load book-service:4.0          | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.30.1 | 20 Mar 25 14:28 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| image      | load book-service:4.0          | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.30.1 | 20 Mar 25 14:33 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
| image      | load book-service:4.0          | minikube | DESKTOP-34O55UA\Nabila Nur     | v1.30.1 | 20 Mar 25 14:37 +07 |                     |
|            |                                |          | Fadhilah                       |         |                     |                     |
|------------|--------------------------------|----------|--------------------------------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2025/03/20 14:23:37
Running on machine: DESKTOP-34O55UA
Binary: Built with gc go1.20.2 for windows/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0320 14:23:37.972029   19768 out.go:296] Setting OutFile to fd 108 ...
I0320 14:23:37.973199   19768 out.go:343] TERM=,COLORTERM=, which probably does not support color
I0320 14:23:37.973199   19768 out.go:309] Setting ErrFile to fd 112...
I0320 14:23:37.973199   19768 out.go:343] TERM=,COLORTERM=, which probably does not support color
I0320 14:23:37.995825   19768 out.go:303] Setting JSON to false
I0320 14:23:38.004796   19768 start.go:125] hostinfo: {"hostname":"DESKTOP-34O55UA","uptime":57433,"bootTime":1742397984,"procs":304,"os":"windows","platform":"Microsoft Windows 11 Home Single Language","platformFamily":"Standalone Workstation","platformVersion":"10.0.26100.3476 Build 26100.3476","kernelVersion":"10.0.26100.3476 Build 26100.3476","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"dfe2cb7b-bf45-440f-9bcd-441f59e73ca2"}
W0320 14:23:38.004796   19768 start.go:133] gopshost.Virtualization returned error: not implemented yet
I0320 14:23:38.025333   19768 out.go:177] * minikube v1.30.1 on Microsoft Windows 11 Home Single Language 10.0.26100.3476 Build 26100.3476
I0320 14:23:38.027356   19768 notify.go:220] Checking for updates...
I0320 14:23:38.029038   19768 driver.go:375] Setting default libvirt URI to qemu:///system
I0320 14:23:38.029038   19768 global.go:111] Querying for installed drivers using PATH=C:\Program Files\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Java\jdk-21\bin;C:\Program Files\apache-maven-3.9.9\bin;C:\Program Files\Git\cmd;C:\Program Files\Docker\Docker\resources\bin;C:\Program Files\MySQL\MySQL Server 8.0\bin;C:\Program Files\nodejs\;C:\xampp\mysql\bin;C:\php;C:\ProgramData\ComposerSetup\bin;C:\Windows\System32;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Nabila Nur Fadhilah\AppData\Local\Microsoft\WindowsApps;C:\Users\Nabila Nur Fadhilah\AppData\Local\Programs\Microsoft VS Code\bin;C:\Program Files\Java\jdk-21\bin;C:\Program Files\apache-maven-3.9.9\bin;C:\Users\Nabila Nur Fadhilah\AppData\Roaming\npm;C:\Users\Nabila Nur Fadhilah\AppData\Roaming\Composer\vendor\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2024.3.4.1\bin;
I0320 14:23:40.463987   19768 global.go:122] hyperv default: true priority: 8, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0320 14:23:40.472520   19768 global.go:122] podman default: true priority: 3, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "podman": executable file not found in %!P(MISSING)ATH%!R(MISSING)eason: Fix:Install Podman Doc:https://minikube.sigs.k8s.io/docs/drivers/podman/ Version:}
I0320 14:23:40.481030   19768 global.go:122] qemu2 default: true priority: 3, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "qemu-system-x86_64": executable file not found in %!P(MISSING)ATH%!R(MISSING)eason: Fix:Install qemu-system Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/qemu/ Version:}
I0320 14:23:40.481030   19768 global.go:122] ssh default: false priority: 4, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0320 14:23:40.500498   19768 global.go:122] virtualbox default: true priority: 6, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:unable to find VBoxManage in $PATH Reason: Fix:Install VirtualBox Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/virtualbox/ Version:}
I0320 14:23:40.508297   19768 global.go:122] vmware default: false priority: 5, state: {Installed:false Healthy:false Running:false NeedsImprovement:false Error:exec: "docker-machine-driver-vmware": executable file not found in %!P(MISSING)ATH%!R(MISSING)eason: Fix:Install docker-machine-driver-vmware Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/ Version:}
I0320 14:23:40.936452   19768 docker.go:121] docker version: linux-27.4.0:Docker Desktop 4.37.1 (178610)
I0320 14:23:40.960605   19768 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0320 14:24:13.138344   19768 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (32.1777391s)
I0320 14:24:13.172266   19768 info.go:266] docker info: {ID:41591fb9-85c6-4e1d-9d4a-3840d7246a3a Containers:19 ContainersRunning:0 ContainersPaused:0 ContainersStopped:19 Images:24 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:55 OomKillDisable:true NGoroutines:84 SystemTime:2025-03-20 07:24:13.017063243 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:16 KernelVersion:5.15.167.4-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:2890686464 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[com.docker.desktop.address=npipe://\\.\pipe\docker_cli] ExperimentalBuild:false ServerVersion:27.4.0 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:472731909fa34bd7bc9c087e4c27943f9835f111 Expected:472731909fa34bd7bc9c087e4c27943f9835f111} RuncCommit:{ID:v1.1.13-0-g58aa920 Expected:v1.1.13-0-g58aa920} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:ai Path:C:\Program Files\Docker\cli-plugins\docker-ai.exe SchemaVersion:0.1.0 ShortDescription:Ask Gordon - Docker Agent Vendor:Docker Inc. Version:v0.5.1] map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.19.2-desktop.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.31.0-desktop.2] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container Vendor:Docker Inc. Version:0.0.37] map[Name:desktop Path:C:\Program Files\Docker\cli-plugins\docker-desktop.exe SchemaVersion:0.1.0 ShortDescription:Docker Desktop commands (Beta) Vendor:Docker Inc. Version:v0.1.0] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.27] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.5] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.4.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.15.1]] Warnings:<nil>}}
I0320 14:24:13.172880   19768 global.go:122] docker default: true priority: 9, state: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0320 14:24:13.173530   19768 driver.go:310] not recommending "ssh" due to default: false
I0320 14:24:13.173530   19768 driver.go:345] Picked: docker
I0320 14:24:13.173530   19768 driver.go:346] Alternatives: [hyperv ssh]
I0320 14:24:13.173530   19768 driver.go:347] Rejects: [podman qemu2 virtualbox vmware]
I0320 14:24:13.175943   19768 out.go:177] * Automatically selected the docker driver. Other choices: hyperv, ssh
I0320 14:24:13.178021   19768 start.go:295] selected driver: docker
I0320 14:24:13.178534   19768 start.go:870] validating driver "docker" against <nil>
I0320 14:24:13.178534   19768 start.go:881] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0320 14:24:13.216761   19768 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0320 14:24:44.975558   19768 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (31.7587966s)
I0320 14:24:44.976233   19768 info.go:266] docker info: {ID:41591fb9-85c6-4e1d-9d4a-3840d7246a3a Containers:19 ContainersRunning:0 ContainersPaused:0 ContainersStopped:19 Images:24 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:55 OomKillDisable:true NGoroutines:84 SystemTime:2025-03-20 07:24:44.82476055 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:16 KernelVersion:5.15.167.4-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:2890686464 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[com.docker.desktop.address=npipe://\\.\pipe\docker_cli] ExperimentalBuild:false ServerVersion:27.4.0 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:472731909fa34bd7bc9c087e4c27943f9835f111 Expected:472731909fa34bd7bc9c087e4c27943f9835f111} RuncCommit:{ID:v1.1.13-0-g58aa920 Expected:v1.1.13-0-g58aa920} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:ai Path:C:\Program Files\Docker\cli-plugins\docker-ai.exe SchemaVersion:0.1.0 ShortDescription:Ask Gordon - Docker Agent Vendor:Docker Inc. Version:v0.5.1] map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.19.2-desktop.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.31.0-desktop.2] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container Vendor:Docker Inc. Version:0.0.37] map[Name:desktop Path:C:\Program Files\Docker\cli-plugins\docker-desktop.exe SchemaVersion:0.1.0 ShortDescription:Docker Desktop commands (Beta) Vendor:Docker Inc. Version:v0.1.0] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.27] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.5] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.4.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.15.1]] Warnings:<nil>}}
I0320 14:24:44.978929   19768 start_flags.go:305] no existing cluster config was found, will generate one from the flags 
I0320 14:24:45.315394   19768 start_flags.go:386] Using suggested 2200MB memory alloc based on sys=5702MB, container=2756MB
I0320 14:24:45.325020   19768 start_flags.go:901] Wait components to verify : map[apiserver:true system_pods:true]
I0320 14:24:45.326236   19768 out.go:177] * Using Docker Desktop driver with root privileges
I0320 14:24:45.329213   19768 cni.go:84] Creating CNI manager for ""
I0320 14:24:45.329834   19768 cni.go:157] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0320 14:24:45.329834   19768 start_flags.go:314] Found "bridge CNI" CNI - setting NetworkPlugin=cni
I0320 14:24:45.329834   19768 start_flags.go:319] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Nabila Nur Fadhilah:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0320 14:24:45.334163   19768 out.go:177] * Starting control plane node minikube in cluster minikube
I0320 14:24:45.338973   19768 cache.go:120] Beginning downloading kic base image for docker with docker
I0320 14:24:45.340248   19768 out.go:177] * Pulling base image ...
I0320 14:24:45.343822   19768 preload.go:132] Checking if preload exists for k8s version v1.26.3 and runtime docker
I0320 14:24:45.345241   19768 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 in local docker daemon
I0320 14:24:45.345874   19768 preload.go:148] Found local preload: C:\Users\Nabila Nur Fadhilah\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.26.3-docker-overlay2-amd64.tar.lz4
I0320 14:24:45.346532   19768 cache.go:57] Caching tarball of preloaded images
I0320 14:24:45.349322   19768 preload.go:174] Found C:\Users\Nabila Nur Fadhilah\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.26.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0320 14:24:45.349322   19768 cache.go:60] Finished verifying existence of preloaded tar for  v1.26.3 on docker
I0320 14:24:45.352458   19768 profile.go:148] Saving config to C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\config.json ...
I0320 14:24:45.353522   19768 lock.go:35] WriteFile acquiring C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\config.json: {Name:mka2ee63fc8140c70a68cd53c63a9da336766dff Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:24:45.542170   19768 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 in local docker daemon, skipping pull
I0320 14:24:45.542170   19768 cache.go:143] gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 exists in daemon, skipping load
I0320 14:24:45.544889   19768 cache.go:193] Successfully downloaded all kic artifacts
I0320 14:24:45.548681   19768 start.go:364] acquiring machines lock for minikube: {Name:mk322e368c94c4cc1c28bd5c62d3bce86222a045 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0320 14:24:45.548681   19768 start.go:368] acquired machines lock for "minikube" in 0s
I0320 14:24:45.550616   19768 start.go:93] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.26.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Nabila Nur Fadhilah:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:} &{Name: IP: Port:8443 KubernetesVersion:v1.26.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0320 14:24:45.551259   19768 start.go:125] createHost starting for "" (driver="docker")
I0320 14:24:45.553181   19768 out.go:204] * Creating docker container (CPUs=2, Memory=2200MB) ...
I0320 14:24:45.559600   19768 start.go:159] libmachine.API.Create for "minikube" (driver="docker")
I0320 14:24:45.560612   19768 client.go:168] LocalClient.Create starting
I0320 14:24:45.565571   19768 main.go:141] libmachine: Reading certificate data from C:\Users\Nabila Nur Fadhilah\.minikube\certs\ca.pem
I0320 14:24:45.567471   19768 main.go:141] libmachine: Decoding PEM data...
I0320 14:24:45.568058   19768 main.go:141] libmachine: Parsing certificate...
I0320 14:24:45.574702   19768 main.go:141] libmachine: Reading certificate data from C:\Users\Nabila Nur Fadhilah\.minikube\certs\cert.pem
I0320 14:24:45.575935   19768 main.go:141] libmachine: Decoding PEM data...
I0320 14:24:45.575935   19768 main.go:141] libmachine: Parsing certificate...
I0320 14:24:45.605540   19768 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W0320 14:24:45.871196   19768 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I0320 14:24:45.890155   19768 network_create.go:281] running [docker network inspect minikube] to gather additional debugging logs...
I0320 14:24:45.892423   19768 cli_runner.go:164] Run: docker network inspect minikube
W0320 14:24:46.027910   19768 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I0320 14:24:46.027910   19768 network_create.go:284] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error response from daemon: network minikube not found
I0320 14:24:46.027910   19768 network_create.go:286] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error response from daemon: network minikube not found

** /stderr **
I0320 14:24:46.047226   19768 cli_runner.go:164] Run: docker network inspect bridge --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0320 14:24:46.450188   19768 network.go:209] using free private subnet 192.168.49.0/24: &{IP:192.168.49.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.49.0/24 Gateway:192.168.49.1 ClientMin:192.168.49.2 ClientMax:192.168.49.254 Broadcast:192.168.49.255 IsPrivate:true Interface:{IfaceName: IfaceIPv4: IfaceMTU:0 IfaceMAC:} reservation:0xc00065c840}
I0320 14:24:46.450188   19768 network_create.go:123] attempt to create docker network minikube 192.168.49.0/24 with gateway 192.168.49.1 and MTU of 1500 ...
I0320 14:24:46.469803   19768 cli_runner.go:164] Run: docker network create --driver=bridge --subnet=192.168.49.0/24 --gateway=192.168.49.1 -o --ip-masq -o --icc -o com.docker.network.driver.mtu=1500 --label=created_by.minikube.sigs.k8s.io=true --label=name.minikube.sigs.k8s.io=minikube minikube
I0320 14:24:46.862313   19768 network_create.go:107] docker network minikube 192.168.49.0/24 created
I0320 14:24:46.863570   19768 kic.go:117] calculated static IP "192.168.49.2" for the "minikube" container
I0320 14:24:46.899816   19768 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0320 14:24:47.083825   19768 cli_runner.go:164] Run: docker volume create minikube --label name.minikube.sigs.k8s.io=minikube --label created_by.minikube.sigs.k8s.io=true
I0320 14:24:47.252598   19768 oci.go:103] Successfully created a docker volume minikube
I0320 14:24:47.272474   19768 cli_runner.go:164] Run: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 -d /var/lib
I0320 14:24:50.506752   19768 cli_runner.go:217] Completed: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 -d /var/lib: (3.2342776s)
I0320 14:24:50.506752   19768 oci.go:107] Successfully prepared a docker volume minikube
I0320 14:24:50.506752   19768 preload.go:132] Checking if preload exists for k8s version v1.26.3 and runtime docker
I0320 14:24:50.506752   19768 kic.go:190] Starting extracting preloaded images to volume ...
I0320 14:24:50.535075   19768 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v "C:\Users\Nabila Nur Fadhilah\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.26.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro" -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 -I lz4 -xf /preloaded.tar -C /extractDir
I0320 14:25:04.475208   19768 cli_runner.go:217] Completed: docker run --rm --entrypoint /usr/bin/tar -v "C:\Users\Nabila Nur Fadhilah\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.26.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro" -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 -I lz4 -xf /preloaded.tar -C /extractDir: (13.9307097s)
I0320 14:25:04.510946   19768 kic.go:199] duration metric: took 13.996264 seconds to extract preloaded images to volume
I0320 14:25:04.682859   19768 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0320 14:25:37.039521   19768 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (32.3435811s)
I0320 14:25:37.069084   19768 info.go:266] docker info: {ID:41591fb9-85c6-4e1d-9d4a-3840d7246a3a Containers:19 ContainersRunning:0 ContainersPaused:0 ContainersStopped:19 Images:24 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:55 OomKillDisable:true NGoroutines:84 SystemTime:2025-03-20 07:25:36.746225108 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:16 KernelVersion:5.15.167.4-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:2890686464 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[com.docker.desktop.address=npipe://\\.\pipe\docker_cli] ExperimentalBuild:false ServerVersion:27.4.0 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:472731909fa34bd7bc9c087e4c27943f9835f111 Expected:472731909fa34bd7bc9c087e4c27943f9835f111} RuncCommit:{ID:v1.1.13-0-g58aa920 Expected:v1.1.13-0-g58aa920} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:ai Path:C:\Program Files\Docker\cli-plugins\docker-ai.exe SchemaVersion:0.1.0 ShortDescription:Ask Gordon - Docker Agent Vendor:Docker Inc. Version:v0.5.1] map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.19.2-desktop.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.31.0-desktop.2] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container Vendor:Docker Inc. Version:0.0.37] map[Name:desktop Path:C:\Program Files\Docker\cli-plugins\docker-desktop.exe SchemaVersion:0.1.0 ShortDescription:Docker Desktop commands (Beta) Vendor:Docker Inc. Version:v0.1.0] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.27] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.5] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.4.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.15.1]] Warnings:<nil>}}
I0320 14:25:37.132306   19768 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0320 14:26:09.302861   19768 cli_runner.go:217] Completed: docker info --format "'{{json .SecurityOptions}}'": (32.1705557s)
I0320 14:26:09.360988   19768 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.49.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=2200mb --memory-swap=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106
I0320 14:26:11.043651   19768 cli_runner.go:217] Completed: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.49.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=2200mb --memory-swap=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106: (1.6820687s)
I0320 14:26:11.059948   19768 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Running}}
I0320 14:26:11.225910   19768 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0320 14:26:11.354588   19768 cli_runner.go:164] Run: docker exec minikube stat /var/lib/dpkg/alternatives/iptables
I0320 14:26:11.570025   19768 oci.go:144] the created container "minikube" has a running status.
I0320 14:26:11.571715   19768 kic.go:221] Creating ssh key for kic: C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa...
I0320 14:26:12.034874   19768 kic_runner.go:191] docker (temp): C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0320 14:26:12.380814   19768 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0320 14:26:12.541843   19768 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0320 14:26:12.541843   19768 kic_runner.go:114] Args: [docker exec --privileged minikube chown docker:docker /home/docker/.ssh/authorized_keys]
I0320 14:26:12.757619   19768 kic.go:261] ensuring only current user has permissions to key file located at : C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa...
I0320 14:26:13.858754   19768 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0320 14:26:14.020094   19768 machine.go:88] provisioning docker machine ...
I0320 14:26:14.026720   19768 ubuntu.go:169] provisioning hostname "minikube"
I0320 14:26:14.047446   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:14.210406   19768 main.go:141] libmachine: Using SSH client type: native
I0320 14:26:14.226304   19768 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x11a8640] 0x11ab500 <nil>  [] 0s} 127.0.0.1 60351 <nil> <nil>}
I0320 14:26:14.226881   19768 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0320 14:26:14.502372   19768 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0320 14:26:14.522093   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:14.699533   19768 main.go:141] libmachine: Using SSH client type: native
I0320 14:26:14.701927   19768 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x11a8640] 0x11ab500 <nil>  [] 0s} 127.0.0.1 60351 <nil> <nil>}
I0320 14:26:14.701927   19768 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0320 14:26:14.864914   19768 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0320 14:26:14.865501   19768 ubuntu.go:175] set auth options {CertDir:C:\Users\Nabila Nur Fadhilah\.minikube CaCertPath:C:\Users\Nabila Nur Fadhilah\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\Nabila Nur Fadhilah\.minikube\machines\server.pem ServerKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\Nabila Nur Fadhilah\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\Nabila Nur Fadhilah\.minikube}
I0320 14:26:14.866080   19768 ubuntu.go:177] setting up certificates
I0320 14:26:14.866653   19768 provision.go:83] configureAuth start
I0320 14:26:14.901361   19768 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0320 14:26:15.076264   19768 provision.go:138] copyHostCerts
I0320 14:26:15.103865   19768 exec_runner.go:144] found C:\Users\Nabila Nur Fadhilah\.minikube/key.pem, removing ...
I0320 14:26:15.104510   19768 exec_runner.go:207] rm: C:\Users\Nabila Nur Fadhilah\.minikube\key.pem
I0320 14:26:15.106963   19768 exec_runner.go:151] cp: C:\Users\Nabila Nur Fadhilah\.minikube\certs\key.pem --> C:\Users\Nabila Nur Fadhilah\.minikube/key.pem (1679 bytes)
I0320 14:26:15.113989   19768 exec_runner.go:144] found C:\Users\Nabila Nur Fadhilah\.minikube/ca.pem, removing ...
I0320 14:26:15.113989   19768 exec_runner.go:207] rm: C:\Users\Nabila Nur Fadhilah\.minikube\ca.pem
I0320 14:26:15.114986   19768 exec_runner.go:151] cp: C:\Users\Nabila Nur Fadhilah\.minikube\certs\ca.pem --> C:\Users\Nabila Nur Fadhilah\.minikube/ca.pem (1111 bytes)
I0320 14:26:15.123253   19768 exec_runner.go:144] found C:\Users\Nabila Nur Fadhilah\.minikube/cert.pem, removing ...
I0320 14:26:15.123253   19768 exec_runner.go:207] rm: C:\Users\Nabila Nur Fadhilah\.minikube\cert.pem
I0320 14:26:15.125277   19768 exec_runner.go:151] cp: C:\Users\Nabila Nur Fadhilah\.minikube\certs\cert.pem --> C:\Users\Nabila Nur Fadhilah\.minikube/cert.pem (1155 bytes)
I0320 14:26:15.128548   19768 provision.go:112] generating server cert: C:\Users\Nabila Nur Fadhilah\.minikube\machines\server.pem ca-key=C:\Users\Nabila Nur Fadhilah\.minikube\certs\ca.pem private-key=C:\Users\Nabila Nur Fadhilah\.minikube\certs\ca-key.pem org=Nabila Nur Fadhilah.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0320 14:26:15.879436   19768 provision.go:172] copyRemoteCerts
I0320 14:26:15.890355   19768 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0320 14:26:15.908764   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:16.100388   19768 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60351 SSHKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa Username:docker}
I0320 14:26:16.216114   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1111 bytes)
I0320 14:26:16.246978   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\machines\server.pem --> /etc/docker/server.pem (1237 bytes)
I0320 14:26:16.275698   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0320 14:26:16.301886   19768 provision.go:86] duration metric: configureAuth took 1.4345658s
I0320 14:26:16.302486   19768 ubuntu.go:193] setting minikube options for container-runtime
I0320 14:26:16.315060   19768 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.26.3
I0320 14:26:16.336269   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:16.504661   19768 main.go:141] libmachine: Using SSH client type: native
I0320 14:26:16.507129   19768 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x11a8640] 0x11ab500 <nil>  [] 0s} 127.0.0.1 60351 <nil> <nil>}
I0320 14:26:16.507129   19768 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0320 14:26:16.703683   19768 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0320 14:26:16.703683   19768 ubuntu.go:71] root file system type: overlay
I0320 14:26:16.707480   19768 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0320 14:26:16.725935   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:16.855302   19768 main.go:141] libmachine: Using SSH client type: native
I0320 14:26:16.856387   19768 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x11a8640] 0x11ab500 <nil>  [] 0s} 127.0.0.1 60351 <nil> <nil>}
I0320 14:26:16.856387   19768 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0320 14:26:17.026269   19768 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0320 14:26:17.045700   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:17.258895   19768 main.go:141] libmachine: Using SSH client type: native
I0320 14:26:17.260553   19768 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x11a8640] 0x11ab500 <nil>  [] 0s} 127.0.0.1 60351 <nil> <nil>}
I0320 14:26:17.260553   19768 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0320 14:26:18.361600   19768 main.go:141] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2023-03-27 16:16:18.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2025-03-20 07:26:17.010135755 +0000
@@ -1,30 +1,32 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service time-set.target
-Wants=network-online.target containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
+Wants=network-online.target
 Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutStartSec=0
-RestartSec=2
-Restart=always
+Restart=on-failure
 
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
@@ -32,16 +34,16 @@
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0320 14:26:18.361600   19768 machine.go:91] provisioned docker machine in 4.3415062s
I0320 14:26:18.362147   19768 client.go:171] LocalClient.Create took 1m32.8009876s
I0320 14:26:18.362147   19768 start.go:167] duration metric: libmachine.API.Create for "minikube" took 1m32.8025468s
I0320 14:26:18.362694   19768 start.go:300] post-start starting for "minikube" (driver="docker")
I0320 14:26:18.362694   19768 start.go:328] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0320 14:26:18.367282   19768 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0320 14:26:18.377361   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:18.499508   19768 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60351 SSHKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa Username:docker}
I0320 14:26:18.636413   19768 ssh_runner.go:195] Run: cat /etc/os-release
I0320 14:26:18.643518   19768 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0320 14:26:18.643518   19768 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0320 14:26:18.643518   19768 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0320 14:26:18.644067   19768 info.go:137] Remote host: Ubuntu 20.04.5 LTS
I0320 14:26:18.644067   19768 filesync.go:126] Scanning C:\Users\Nabila Nur Fadhilah\.minikube\addons for local assets ...
I0320 14:26:18.645713   19768 filesync.go:126] Scanning C:\Users\Nabila Nur Fadhilah\.minikube\files for local assets ...
I0320 14:26:18.646778   19768 start.go:303] post-start completed in 284.0834ms
I0320 14:26:18.676384   19768 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0320 14:26:18.815689   19768 profile.go:148] Saving config to C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\config.json ...
I0320 14:26:18.900751   19768 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0320 14:26:18.924722   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:19.063088   19768 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60351 SSHKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa Username:docker}
I0320 14:26:19.254976   19768 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0320 14:26:19.261296   19768 start.go:128] duration metric: createHost completed in 1m33.7100373s
I0320 14:26:19.261916   19768 start.go:83] releasing machines lock for "minikube", held for 1m33.7132351s
I0320 14:26:19.284623   19768 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0320 14:26:19.424762   19768 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0320 14:26:19.449866   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:19.481665   19768 ssh_runner.go:195] Run: cat /version.json
I0320 14:26:19.500677   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:19.606924   19768 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60351 SSHKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa Username:docker}
I0320 14:26:19.637618   19768 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60351 SSHKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa Username:docker}
I0320 14:26:20.572388   19768 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (1.1476256s)
I0320 14:26:20.572388   19768 ssh_runner.go:235] Completed: cat /version.json: (1.0907225s)
I0320 14:26:20.649701   19768 ssh_runner.go:195] Run: systemctl --version
I0320 14:26:20.711647   19768 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0320 14:26:20.723889   19768 ssh_runner.go:195] Run: sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
W0320 14:26:20.737648   19768 start.go:408] unable to name loopback interface in configureRuntimes: unable to patch loopback cni config "/etc/cni/net.d/*loopback.conf*": sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;: Process exited with status 1
stdout:

stderr:
find: '\\etc\\cni\\net.d': No such file or directory
I0320 14:26:20.743493   19768 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0320 14:26:20.765338   19768 cni.go:261] disabled [/etc/cni/net.d/100-crio-bridge.conf] bridge cni config(s)
I0320 14:26:20.765917   19768 start.go:481] detecting cgroup driver to use...
I0320 14:26:20.765917   19768 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0320 14:26:20.769897   19768 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0320 14:26:20.835420   19768 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0320 14:26:20.896682   19768 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0320 14:26:20.911711   19768 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0320 14:26:20.962884   19768 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0320 14:26:21.019610   19768 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0320 14:26:21.083716   19768 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0320 14:26:21.135582   19768 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0320 14:26:21.202408   19768 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0320 14:26:21.261680   19768 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0320 14:26:21.281329   19768 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0320 14:26:21.296203   19768 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0320 14:26:21.308274   19768 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0320 14:26:21.407882   19768 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0320 14:26:21.534068   19768 start.go:481] detecting cgroup driver to use...
I0320 14:26:21.534068   19768 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0320 14:26:21.538202   19768 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0320 14:26:21.552461   19768 cruntime.go:276] skipping containerd shutdown because we are bound to it
I0320 14:26:21.555775   19768 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0320 14:26:21.569063   19768 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0320 14:26:21.614342   19768 ssh_runner.go:195] Run: which cri-dockerd
I0320 14:26:21.624028   19768 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0320 14:26:21.640505   19768 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0320 14:26:21.670351   19768 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0320 14:26:21.780849   19768 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0320 14:26:21.892853   19768 docker.go:538] configuring docker to use "cgroupfs" as cgroup driver...
I0320 14:26:21.893373   19768 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (144 bytes)
I0320 14:26:21.923583   19768 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0320 14:26:22.016654   19768 ssh_runner.go:195] Run: sudo systemctl restart docker
I0320 14:26:22.303485   19768 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0320 14:26:22.414621   19768 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0320 14:26:22.513202   19768 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0320 14:26:22.642341   19768 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0320 14:26:22.743210   19768 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0320 14:26:22.761467   19768 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0320 14:26:22.894002   19768 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0320 14:26:23.139479   19768 start.go:528] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0320 14:26:23.184753   19768 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0320 14:26:23.192043   19768 start.go:549] Will wait 60s for crictl version
I0320 14:26:23.230338   19768 ssh_runner.go:195] Run: which crictl
I0320 14:26:23.239840   19768 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0320 14:26:23.410673   19768 start.go:565] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  23.0.2
RuntimeApiVersion:  v1alpha2
I0320 14:26:23.427344   19768 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0320 14:26:23.542004   19768 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0320 14:26:23.583711   19768 out.go:204] * Preparing Kubernetes v1.26.3 on Docker 23.0.2 ...
I0320 14:26:23.613915   19768 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0320 14:26:23.881184   19768 network.go:96] got host ip for mount in container by digging dns: 192.168.65.254
I0320 14:26:23.918287   19768 ssh_runner.go:195] Run: grep 192.168.65.254	host.minikube.internal$ /etc/hosts
I0320 14:26:23.927034   19768 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.254	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0320 14:26:23.951687   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0320 14:26:24.092172   19768 preload.go:132] Checking if preload exists for k8s version v1.26.3 and runtime docker
I0320 14:26:24.108217   19768 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0320 14:26:24.141322   19768 docker.go:639] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.26.3
registry.k8s.io/kube-scheduler:v1.26.3
registry.k8s.io/kube-controller-manager:v1.26.3
registry.k8s.io/kube-proxy:v1.26.3
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/pause:3.9
registry.k8s.io/coredns/coredns:v1.9.3
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0320 14:26:24.141322   19768 docker.go:569] Images already preloaded, skipping extraction
I0320 14:26:24.152580   19768 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0320 14:26:24.173072   19768 docker.go:639] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.26.3
registry.k8s.io/kube-scheduler:v1.26.3
registry.k8s.io/kube-controller-manager:v1.26.3
registry.k8s.io/kube-proxy:v1.26.3
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/pause:3.9
registry.k8s.io/coredns/coredns:v1.9.3
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0320 14:26:24.173072   19768 cache_images.go:84] Images are preloaded, skipping loading
I0320 14:26:24.184199   19768 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0320 14:26:24.208564   19768 cni.go:84] Creating CNI manager for ""
I0320 14:26:24.208564   19768 cni.go:157] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0320 14:26:24.214092   19768 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0320 14:26:24.214092   19768 kubeadm.go:172] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.26.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m]}
I0320 14:26:24.215697   19768 kubeadm.go:177] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.26.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0320 14:26:24.216777   19768 kubeadm.go:968] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.26.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0320 14:26:24.219547   19768 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.26.3
I0320 14:26:24.233930   19768 binaries.go:44] Found k8s binaries, skipping transfer
I0320 14:26:24.241916   19768 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0320 14:26:24.252146   19768 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (369 bytes)
I0320 14:26:24.266354   19768 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0320 14:26:24.282205   19768 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2084 bytes)
I0320 14:26:24.326353   19768 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0320 14:26:24.332300   19768 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0320 14:26:24.344599   19768 certs.go:56] Setting up C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube for IP: 192.168.49.2
I0320 14:26:24.346292   19768 certs.go:186] acquiring lock for shared ca certs: {Name:mk94e30cdf976bbdf1a8e6c7f6a1c3de5bf6897c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:26:24.350808   19768 certs.go:195] skipping minikubeCA CA generation: C:\Users\Nabila Nur Fadhilah\.minikube\ca.key
I0320 14:26:24.352942   19768 certs.go:195] skipping proxyClientCA CA generation: C:\Users\Nabila Nur Fadhilah\.minikube\proxy-client-ca.key
I0320 14:26:24.357881   19768 certs.go:315] generating minikube-user signed cert: C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\client.key
I0320 14:26:24.364026   19768 crypto.go:68] Generating cert C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\client.crt with IP's: []
I0320 14:26:24.836933   19768 crypto.go:156] Writing cert to C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\client.crt ...
I0320 14:26:24.836933   19768 lock.go:35] WriteFile acquiring C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\client.crt: {Name:mk2da4f0be063ffb1334e64988eb415cffb58a35 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:26:24.836933   19768 crypto.go:164] Writing key to C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\client.key ...
I0320 14:26:24.836933   19768 lock.go:35] WriteFile acquiring C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\client.key: {Name:mk3e83232c2a685790b9ca7667c8f428dc3c9922 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:26:24.836933   19768 certs.go:315] generating minikube signed cert: C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.key.dd3b5fb2
I0320 14:26:24.836933   19768 crypto.go:68] Generating cert C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2 with IP's: [192.168.49.2 10.96.0.1 127.0.0.1 10.0.0.1]
I0320 14:26:25.544305   19768 crypto.go:156] Writing cert to C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2 ...
I0320 14:26:25.544305   19768 lock.go:35] WriteFile acquiring C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2: {Name:mkbeeb8097fb2bb94d1c4af63bddd7b2f082be4b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:26:25.550926   19768 crypto.go:164] Writing key to C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.key.dd3b5fb2 ...
I0320 14:26:25.550926   19768 lock.go:35] WriteFile acquiring C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.key.dd3b5fb2: {Name:mk577c96d5ee561e481d5d1ba1521f0128afd9ed Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:26:25.554608   19768 certs.go:333] copying C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2 -> C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.crt
I0320 14:26:25.554608   19768 certs.go:337] copying C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.key.dd3b5fb2 -> C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.key
I0320 14:26:25.566766   19768 certs.go:315] generating aggregator signed cert: C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\proxy-client.key
I0320 14:26:25.566766   19768 crypto.go:68] Generating cert C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\proxy-client.crt with IP's: []
I0320 14:26:25.900975   19768 crypto.go:156] Writing cert to C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\proxy-client.crt ...
I0320 14:26:25.900975   19768 lock.go:35] WriteFile acquiring C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\proxy-client.crt: {Name:mk76a237e21fe0bbd2130d747653edc9f63be3a9 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:26:25.903202   19768 crypto.go:164] Writing key to C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\proxy-client.key ...
I0320 14:26:25.903202   19768 lock.go:35] WriteFile acquiring C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\proxy-client.key: {Name:mkf22e1a278b6dc1b6c2b0456357a9f317167ee6 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:26:25.913434   19768 certs.go:401] found cert: C:\Users\Nabila Nur Fadhilah\.minikube\certs\C:\Users\Nabila Nur Fadhilah\.minikube\certs\ca-key.pem (1679 bytes)
I0320 14:26:25.914487   19768 certs.go:401] found cert: C:\Users\Nabila Nur Fadhilah\.minikube\certs\C:\Users\Nabila Nur Fadhilah\.minikube\certs\ca.pem (1111 bytes)
I0320 14:26:25.915036   19768 certs.go:401] found cert: C:\Users\Nabila Nur Fadhilah\.minikube\certs\C:\Users\Nabila Nur Fadhilah\.minikube\certs\cert.pem (1155 bytes)
I0320 14:26:25.915566   19768 certs.go:401] found cert: C:\Users\Nabila Nur Fadhilah\.minikube\certs\C:\Users\Nabila Nur Fadhilah\.minikube\certs\key.pem (1679 bytes)
I0320 14:26:25.952621   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0320 14:26:25.974485   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0320 14:26:25.991971   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0320 14:26:26.009841   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\profiles\minikube\proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0320 14:26:26.027820   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0320 14:26:26.044878   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0320 14:26:26.063109   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0320 14:26:26.093579   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0320 14:26:26.113208   19768 ssh_runner.go:362] scp C:\Users\Nabila Nur Fadhilah\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0320 14:26:26.133322   19768 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0320 14:26:26.191309   19768 ssh_runner.go:195] Run: openssl version
I0320 14:26:26.205739   19768 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0320 14:26:26.269123   19768 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0320 14:26:26.277088   19768 certs.go:444] hashing: -rw-r--r-- 1 root root 1111 Mar 20 04:15 /usr/share/ca-certificates/minikubeCA.pem
I0320 14:26:26.317197   19768 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0320 14:26:26.343734   19768 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0320 14:26:26.358323   19768 kubeadm.go:401] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.39@sha256:bf2d9f1e9d837d8deea073611d2605405b6be904647d97ebd9b12045ddfe1106 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.26.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.26.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Nabila Nur Fadhilah:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP:}
I0320 14:26:26.373500   19768 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0320 14:26:26.397548   19768 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0320 14:26:26.410010   19768 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0320 14:26:26.417850   19768 kubeadm.go:226] ignoring SystemVerification for kubeadm because of docker driver
I0320 14:26:26.422462   19768 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0320 14:26:26.431443   19768 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0320 14:26:26.431976   19768 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.26.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0320 14:26:26.557806   19768 kubeadm.go:322] W0320 07:26:26.555962    1428 initconfiguration.go:119] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
I0320 14:26:26.612377   19768 kubeadm.go:322] 	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
I0320 14:26:26.871914   19768 kubeadm.go:322] 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0320 14:26:35.671903   19768 kubeadm.go:322] [init] Using Kubernetes version: v1.26.3
I0320 14:26:35.671903   19768 kubeadm.go:322] [preflight] Running pre-flight checks
I0320 14:26:35.671903   19768 kubeadm.go:322] [preflight] Pulling images required for setting up a Kubernetes cluster
I0320 14:26:35.671903   19768 kubeadm.go:322] [preflight] This might take a minute or two, depending on the speed of your internet connection
I0320 14:26:35.671903   19768 kubeadm.go:322] [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
I0320 14:26:35.671903   19768 kubeadm.go:322] [certs] Using certificateDir folder "/var/lib/minikube/certs"
I0320 14:26:35.672982   19768 out.go:204]   - Generating certificates and keys ...
I0320 14:26:35.673499   19768 kubeadm.go:322] [certs] Using existing ca certificate authority
I0320 14:26:35.673499   19768 kubeadm.go:322] [certs] Using existing apiserver certificate and key on disk
I0320 14:26:35.674066   19768 kubeadm.go:322] [certs] Generating "apiserver-kubelet-client" certificate and key
I0320 14:26:35.674066   19768 kubeadm.go:322] [certs] Generating "front-proxy-ca" certificate and key
I0320 14:26:35.674066   19768 kubeadm.go:322] [certs] Generating "front-proxy-client" certificate and key
I0320 14:26:35.674066   19768 kubeadm.go:322] [certs] Generating "etcd/ca" certificate and key
I0320 14:26:35.674066   19768 kubeadm.go:322] [certs] Generating "etcd/server" certificate and key
I0320 14:26:35.674066   19768 kubeadm.go:322] [certs] etcd/server serving cert is signed for DNS names [localhost minikube] and IPs [192.168.49.2 127.0.0.1 ::1]
I0320 14:26:35.674591   19768 kubeadm.go:322] [certs] Generating "etcd/peer" certificate and key
I0320 14:26:35.674591   19768 kubeadm.go:322] [certs] etcd/peer serving cert is signed for DNS names [localhost minikube] and IPs [192.168.49.2 127.0.0.1 ::1]
I0320 14:26:35.674591   19768 kubeadm.go:322] [certs] Generating "etcd/healthcheck-client" certificate and key
I0320 14:26:35.674591   19768 kubeadm.go:322] [certs] Generating "apiserver-etcd-client" certificate and key
I0320 14:26:35.674591   19768 kubeadm.go:322] [certs] Generating "sa" key and public key
I0320 14:26:35.674591   19768 kubeadm.go:322] [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
I0320 14:26:35.675126   19768 kubeadm.go:322] [kubeconfig] Writing "admin.conf" kubeconfig file
I0320 14:26:35.675126   19768 kubeadm.go:322] [kubeconfig] Writing "kubelet.conf" kubeconfig file
I0320 14:26:35.675126   19768 kubeadm.go:322] [kubeconfig] Writing "controller-manager.conf" kubeconfig file
I0320 14:26:35.675126   19768 kubeadm.go:322] [kubeconfig] Writing "scheduler.conf" kubeconfig file
I0320 14:26:35.675126   19768 kubeadm.go:322] [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I0320 14:26:35.675126   19768 kubeadm.go:322] [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0320 14:26:35.675654   19768 kubeadm.go:322] [kubelet-start] Starting the kubelet
I0320 14:26:35.675654   19768 kubeadm.go:322] [control-plane] Using manifest folder "/etc/kubernetes/manifests"
I0320 14:26:35.676693   19768 out.go:204]   - Booting up control plane ...
I0320 14:26:35.676693   19768 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-apiserver"
I0320 14:26:35.676693   19768 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-controller-manager"
I0320 14:26:35.677225   19768 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-scheduler"
I0320 14:26:35.677225   19768 kubeadm.go:322] [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
I0320 14:26:35.677225   19768 kubeadm.go:322] [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
I0320 14:26:35.677225   19768 kubeadm.go:322] [apiclient] All control plane components are healthy after 6.003499 seconds
I0320 14:26:35.677752   19768 kubeadm.go:322] [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
I0320 14:26:35.677752   19768 kubeadm.go:322] [kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the configuration for the kubelets in the cluster
I0320 14:26:35.677752   19768 kubeadm.go:322] [upload-certs] Skipping phase. Please see --upload-certs
I0320 14:26:35.678281   19768 kubeadm.go:322] [mark-control-plane] Marking the node minikube as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
I0320 14:26:35.678281   19768 kubeadm.go:322] [bootstrap-token] Using token: 4iaz3e.5q6gnr9duqhc9dvi
I0320 14:26:35.678812   19768 out.go:204]   - Configuring RBAC rules ...
I0320 14:26:35.679903   19768 kubeadm.go:322] [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
I0320 14:26:35.679903   19768 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
I0320 14:26:35.680438   19768 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
I0320 14:26:35.680438   19768 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
I0320 14:26:35.680438   19768 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
I0320 14:26:35.680973   19768 kubeadm.go:322] [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
I0320 14:26:35.680973   19768 kubeadm.go:322] [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
I0320 14:26:35.680973   19768 kubeadm.go:322] [addons] Applied essential addon: CoreDNS
I0320 14:26:35.680973   19768 kubeadm.go:322] [addons] Applied essential addon: kube-proxy
I0320 14:26:35.680973   19768 kubeadm.go:322] 
I0320 14:26:35.680973   19768 kubeadm.go:322] Your Kubernetes control-plane has initialized successfully!
I0320 14:26:35.680973   19768 kubeadm.go:322] 
I0320 14:26:35.680973   19768 kubeadm.go:322] To start using your cluster, you need to run the following as a regular user:
I0320 14:26:35.680973   19768 kubeadm.go:322] 
I0320 14:26:35.680973   19768 kubeadm.go:322]   mkdir -p $HOME/.kube
I0320 14:26:35.681507   19768 kubeadm.go:322]   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
I0320 14:26:35.681507   19768 kubeadm.go:322]   sudo chown $(id -u):$(id -g) $HOME/.kube/config
I0320 14:26:35.681507   19768 kubeadm.go:322] 
I0320 14:26:35.681507   19768 kubeadm.go:322] Alternatively, if you are the root user, you can run:
I0320 14:26:35.681507   19768 kubeadm.go:322] 
I0320 14:26:35.681507   19768 kubeadm.go:322]   export KUBECONFIG=/etc/kubernetes/admin.conf
I0320 14:26:35.682254   19768 kubeadm.go:322] 
I0320 14:26:35.682254   19768 kubeadm.go:322] You should now deploy a pod network to the cluster.
I0320 14:26:35.684269   19768 kubeadm.go:322] Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
I0320 14:26:35.684269   19768 kubeadm.go:322]   https://kubernetes.io/docs/concepts/cluster-administration/addons/
I0320 14:26:35.684269   19768 kubeadm.go:322] 
I0320 14:26:35.684269   19768 kubeadm.go:322] You can now join any number of control-plane nodes by copying certificate authorities
I0320 14:26:35.684269   19768 kubeadm.go:322] and service account keys on each node and then running the following as root:
I0320 14:26:35.684269   19768 kubeadm.go:322] 
I0320 14:26:35.684898   19768 kubeadm.go:322]   kubeadm join control-plane.minikube.internal:8443 --token 4iaz3e.5q6gnr9duqhc9dvi \
I0320 14:26:35.684898   19768 kubeadm.go:322] 	--discovery-token-ca-cert-hash sha256:a22776fadcc17e3fd86176409df5984c9ec0a0cb2e3f6ab77ea0760622bfdea3 \
I0320 14:26:35.684898   19768 kubeadm.go:322] 	--control-plane 
I0320 14:26:35.684898   19768 kubeadm.go:322] 
I0320 14:26:35.684898   19768 kubeadm.go:322] Then you can join any number of worker nodes by running the following on each as root:
I0320 14:26:35.684898   19768 kubeadm.go:322] 
I0320 14:26:35.684898   19768 kubeadm.go:322] kubeadm join control-plane.minikube.internal:8443 --token 4iaz3e.5q6gnr9duqhc9dvi \
I0320 14:26:35.684898   19768 kubeadm.go:322] 	--discovery-token-ca-cert-hash sha256:a22776fadcc17e3fd86176409df5984c9ec0a0cb2e3f6ab77ea0760622bfdea3 
I0320 14:26:35.685441   19768 cni.go:84] Creating CNI manager for ""
I0320 14:26:35.685441   19768 cni.go:157] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0320 14:26:35.687696   19768 out.go:177] * Configuring bridge CNI (Container Networking Interface) ...
I0320 14:26:35.693882   19768 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0320 14:26:35.724049   19768 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I0320 14:26:35.743137   19768 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0320 14:26:35.746371   19768 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.26.3/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0320 14:26:35.746886   19768 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.26.3/kubectl label nodes minikube.k8s.io/version=v1.30.1 minikube.k8s.io/commit=08896fd1dc362c097c925146c4a0d0dac715ace0 minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2025_03_20T14_26_35_0700 minikube.k8s.io/primary=true --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I0320 14:26:35.922028   19768 ops.go:34] apiserver oom_adj: -16
I0320 14:26:36.417409   19768 kubeadm.go:1073] duration metric: took 673.7192ms to wait for elevateKubeSystemPrivileges.
I0320 14:26:36.417409   19768 kubeadm.go:403] StartCluster complete in 10.059086s
I0320 14:26:36.417994   19768 settings.go:142] acquiring lock: {Name:mkcad6e6f0422cb37a9a60b4762b57539196269d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:26:36.418614   19768 settings.go:150] Updating kubeconfig:  C:\Users\Nabila Nur Fadhilah\.kube\config
I0320 14:26:36.427637   19768 lock.go:35] WriteFile acquiring C:\Users\Nabila Nur Fadhilah\.kube\config: {Name:mk4f7ddddd799efdf125cde75dafd8c31ccfa7fc Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0320 14:26:36.433970   19768 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0320 14:26:36.437864   19768 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.26.3
I0320 14:26:36.436019   19768 addons.go:496] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false]
I0320 14:26:36.439065   19768 addons.go:66] Setting storage-provisioner=true in profile "minikube"
I0320 14:26:36.439065   19768 addons.go:66] Setting default-storageclass=true in profile "minikube"
I0320 14:26:36.439640   19768 addons.go:228] Setting addon storage-provisioner=true in "minikube"
I0320 14:26:36.439640   19768 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0320 14:26:36.442874   19768 host.go:66] Checking if "minikube" exists ...
I0320 14:26:36.485489   19768 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0320 14:26:36.485489   19768 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0320 14:26:36.521896   19768 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.26.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed -e '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.65.254 host.minikube.internal\n           fallthrough\n        }' -e '/^        errors *$/i \        log' | sudo /var/lib/minikube/binaries/v1.26.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I0320 14:26:36.619382   19768 out.go:177]   - Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0320 14:26:36.621009   19768 addons.go:420] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0320 14:26:36.621009   19768 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0320 14:26:36.632407   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:36.675984   19768 addons.go:228] Setting addon default-storageclass=true in "minikube"
I0320 14:26:36.677060   19768 host.go:66] Checking if "minikube" exists ...
I0320 14:26:36.695785   19768 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0320 14:26:36.738631   19768 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60351 SSHKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa Username:docker}
I0320 14:26:36.801333   19768 addons.go:420] installing /etc/kubernetes/addons/storageclass.yaml
I0320 14:26:36.801333   19768 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0320 14:26:36.816099   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0320 14:26:36.869737   19768 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.26.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0320 14:26:36.940985   19768 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60351 SSHKeyPath:C:\Users\Nabila Nur Fadhilah\.minikube\machines\minikube\id_rsa Username:docker}
I0320 14:26:37.119282   19768 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I0320 14:26:37.119844   19768 start.go:223] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.26.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0320 14:26:37.121642   19768 out.go:177] * Verifying Kubernetes components...
I0320 14:26:37.127846   19768 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0320 14:26:37.143809   19768 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.26.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0320 14:26:37.420261   19768 start.go:916] {"host.minikube.internal": 192.168.65.254} host record injected into CoreDNS's ConfigMap
I0320 14:26:37.476465   19768 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0320 14:26:37.551869   19768 out.go:177] * Enabled addons: storage-provisioner, default-storageclass
I0320 14:26:37.552935   19768 addons.go:499] enable addons completed in 1.1178111s: enabled=[storage-provisioner default-storageclass]
I0320 14:26:37.608283   19768 api_server.go:51] waiting for apiserver process to appear ...
I0320 14:26:37.614253   19768 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0320 14:26:37.623847   19768 api_server.go:71] duration metric: took 504.0034ms to wait for apiserver process to appear ...
I0320 14:26:37.624398   19768 api_server.go:87] waiting for apiserver healthz status ...
I0320 14:26:37.624970   19768 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:60350/healthz ...
I0320 14:26:37.642712   19768 api_server.go:278] https://127.0.0.1:60350/healthz returned 200:
ok
I0320 14:26:37.646001   19768 api_server.go:140] control plane version: v1.26.3
I0320 14:26:37.646001   19768 api_server.go:130] duration metric: took 21.603ms to wait for apiserver health ...
I0320 14:26:37.646638   19768 system_pods.go:43] waiting for kube-system pods to appear ...
I0320 14:26:37.667175   19768 system_pods.go:59] 5 kube-system pods found
I0320 14:26:37.667708   19768 system_pods.go:61] "etcd-minikube" [a0b879a8-cb59-471d-9837-36050a80d58e] Pending
I0320 14:26:37.667708   19768 system_pods.go:61] "kube-apiserver-minikube" [5f8f288f-6b6a-459a-894a-69260e6cb60f] Pending
I0320 14:26:37.667708   19768 system_pods.go:61] "kube-controller-manager-minikube" [63dcc63b-f8e0-40c5-96b1-ad1b5f7b5b12] Pending
I0320 14:26:37.667708   19768 system_pods.go:61] "kube-scheduler-minikube" [7ee72337-e19b-4a8e-b2c6-8d4c02034e60] Pending
I0320 14:26:37.667708   19768 system_pods.go:61] "storage-provisioner" [39e8638e-d6a7-4c78-ac3e-32f6b14618bd] Pending: PodScheduled:Unschedulable (0/1 nodes are available: 1 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..)
I0320 14:26:37.667708   19768 system_pods.go:74] duration metric: took 21.0701ms to wait for pod list to return data ...
I0320 14:26:37.667708   19768 kubeadm.go:578] duration metric: took 547.8639ms to wait for : map[apiserver:true system_pods:true] ...
I0320 14:26:37.668254   19768 node_conditions.go:102] verifying NodePressure condition ...
I0320 14:26:37.669331   19768 node_conditions.go:122] node storage ephemeral capacity is 1055762868Ki
I0320 14:26:37.669331   19768 node_conditions.go:123] node cpu capacity is 8
I0320 14:26:37.669331   19768 node_conditions.go:105] duration metric: took 1.0772ms to run NodePressure ...
I0320 14:26:37.669331   19768 start.go:228] waiting for startup goroutines ...
I0320 14:26:37.669331   19768 start.go:233] waiting for cluster config update ...
I0320 14:26:37.669331   19768 start.go:242] writing updated cluster config ...
I0320 14:26:37.710997   19768 ssh_runner.go:195] Run: rm -f paused
I0320 14:26:38.928697   19768 start.go:568] kubectl: 1.30.5, cluster: 1.26.3 (minor skew: 4)
I0320 14:26:38.929976   19768 out.go:177] 
W0320 14:26:38.932414   19768 out.go:239] ! C:\Program Files\Docker\Docker\resources\bin\kubectl.exe is version 1.30.5, which may have incompatibilities with Kubernetes 1.26.3.
I0320 14:26:38.933613   19768 out.go:177]   - Want kubectl v1.26.3? Try 'minikube kubectl -- get pods -A'
I0320 14:26:38.935308   19768 out.go:177] * Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* -- Logs begin at Thu 2025-03-20 07:26:11 UTC, end at Thu 2025-03-20 07:43:35 UTC. --
Mar 20 07:26:22 minikube dockerd[960]: time="2025-03-20T07:26:22.291844033Z" level=info msg="[core] [Server #7] Server created" module=grpc
Mar 20 07:26:22 minikube systemd[1]: Started Docker Application Container Engine.
Mar 20 07:26:22 minikube dockerd[960]: time="2025-03-20T07:26:22.296998625Z" level=info msg="API listen on [::]:2376"
Mar 20 07:26:22 minikube dockerd[960]: time="2025-03-20T07:26:22.299519604Z" level=info msg="API listen on /var/run/docker.sock"
Mar 20 07:26:22 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Start docker client with request timeout 0s"
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Hairpin mode is set to hairpin-veth"
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Loaded network plugin cni"
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Docker cri networking managed by network plugin cni"
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Docker Info: &{ID:01789322-e1b9-4e3f-b5fa-e3bd7990b20f Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:8 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:24 OomKillDisable:true NGoroutines:32 SystemTime:2025-03-20T07:26:23.127824212Z LoggingDriver:json-file CgroupDriver:cgroupfs CgroupVersion:1 NEventsListener:0 KernelVersion:5.15.167.4-microsoft-standard-WSL2 OperatingSystem:Ubuntu 20.04.5 LTS (containerized) OSVersion:20.04 OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc000134e00 NCPU:8 MemTotal:2890686464 GenericResources:[] DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy:control-plane.minikube.internal Name:minikube Labels:[provider=docker] ExperimentalBuild:false ServerVersion:23.0.2 ClusterStore: ClusterAdvertise: Runtimes:map[io.containerd.runc.v2:{Path:runc Args:[] Shim:<nil>} runc:{Path:runc Args:[] Shim:<nil>}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:<nil> Warnings:[]} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:2806fc1057397dbaeefbea0e4e17bddfbd388f38 Expected:2806fc1057397dbaeefbea0e4e17bddfbd388f38} RuncCommit:{ID:v1.1.5-0-gf19387a Expected:v1.1.5-0-gf19387a} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=builtin] ProductLicense: DefaultAddressPools:[] Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support]}"
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Setting cgroupDriver cgroupfs"
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Mar 20 07:26:23 minikube cri-dockerd[1176]: time="2025-03-20T07:26:23Z" level=info msg="Start cri-dockerd grpc backend"
Mar 20 07:26:23 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Mar 20 07:26:29 minikube cri-dockerd[1176]: time="2025-03-20T07:26:29Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/194560139f51da2926b76211b3507a366773dd50e5366956ab2277eb15839339/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Mar 20 07:26:29 minikube cri-dockerd[1176]: time="2025-03-20T07:26:29Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/b513d58ca5a3b09ba5f5c480b269cc5129954c1b67f6029565e1fe25ab4c98d3/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Mar 20 07:26:29 minikube cri-dockerd[1176]: time="2025-03-20T07:26:29Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/9a3a0d075eb336a82ca7effc14730d9c8f926b13b4e19b836d3d8490c4beda69/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Mar 20 07:26:29 minikube cri-dockerd[1176]: time="2025-03-20T07:26:29Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/2018109a96690115f26f423d708cd68da08fd8b24e92008102715248759338be/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Mar 20 07:26:48 minikube cri-dockerd[1176]: time="2025-03-20T07:26:48Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/e164983598cf5e0db74a754ba33c6e549e58f552cc03348d5034ecbda854b6a2/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Mar 20 07:26:48 minikube cri-dockerd[1176]: time="2025-03-20T07:26:48Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1500978e0f8528d5d798cad45f1e7866d33d617a5a5c2d806eb19b3a6c4e1776/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Mar 20 07:26:49 minikube cri-dockerd[1176]: time="2025-03-20T07:26:49Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/9348db177175c1562ac23919c7b76d6f493262455dd49fe93ffe1764bd4c78e4/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Mar 20 07:26:56 minikube cri-dockerd[1176]: time="2025-03-20T07:26:56Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:10.244.0.0/24,},}"
Mar 20 07:27:09 minikube dockerd[960]: time="2025-03-20T07:27:09.923487736Z" level=info msg="ignoring event" container=606a8d7b1395c1bc5e515f3754b884c838bcec2907ea467844217fadfb56ab09 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 20 07:27:23 minikube cri-dockerd[1176]: time="2025-03-20T07:27:23Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/d661d81d332876d6e929cfab3ec89f8d05787cbf7af08e4d67fc58d1aade2a8b/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Mar 20 07:27:28 minikube dockerd[960]: time="2025-03-20T07:27:28.599940790Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:27:28 minikube dockerd[960]: time="2025-03-20T07:27:28.600020781Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:27:32 minikube dockerd[960]: time="2025-03-20T07:27:32.581036476Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:27:32 minikube dockerd[960]: time="2025-03-20T07:27:32.581115159Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:27:33 minikube dockerd[960]: time="2025-03-20T07:27:33.055981747Z" level=info msg="ignoring event" container=d661d81d332876d6e929cfab3ec89f8d05787cbf7af08e4d67fc58d1aade2a8b module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 20 07:27:33 minikube cri-dockerd[1176]: time="2025-03-20T07:27:33Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/7c889692492f82c6a178d7936515a903fb0730b0d6df2b6ae400a219dc74092d/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Mar 20 07:27:52 minikube dockerd[960]: time="2025-03-20T07:27:52.017408081Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:27:52 minikube dockerd[960]: time="2025-03-20T07:27:52.018464183Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:27:55 minikube dockerd[960]: time="2025-03-20T07:27:55.948281831Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:27:55 minikube dockerd[960]: time="2025-03-20T07:27:55.948355906Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:28:30 minikube dockerd[960]: time="2025-03-20T07:28:29.906198436Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:28:30 minikube dockerd[960]: time="2025-03-20T07:28:29.915764529Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:29:04 minikube dockerd[960]: time="2025-03-20T07:29:04.547814795Z" level=info msg="ignoring event" container=f12a2a64cd13f70879f150cb8f19e7c8117e60e9609fbf29f0aed79fb121494b module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 20 07:29:07 minikube dockerd[960]: time="2025-03-20T07:29:07.536422019Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:29:07 minikube dockerd[960]: time="2025-03-20T07:29:07.674630666Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:30:10 minikube cri-dockerd[1176]: time="2025-03-20T07:30:10Z" level=error msg="Error response from daemon: No such container: 606a8d7b1395c1bc5e515f3754b884c838bcec2907ea467844217fadfb56ab09 Failed to get stats from container 606a8d7b1395c1bc5e515f3754b884c838bcec2907ea467844217fadfb56ab09"
Mar 20 07:30:14 minikube dockerd[960]: time="2025-03-20T07:30:14.063899358Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:30:14 minikube dockerd[960]: time="2025-03-20T07:30:14.067620668Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:30:43 minikube dockerd[960]: time="2025-03-20T07:30:43.306892298Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:30:43 minikube dockerd[960]: time="2025-03-20T07:30:43.333170316Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:31:08 minikube dockerd[960]: time="2025-03-20T07:31:08.198200218Z" level=info msg="ignoring event" container=a58a1180bc062f2b78e5cb9aa6fc7691ae4626d11e9ee6b8cfddc31ae1ec367a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 20 07:31:45 minikube dockerd[960]: time="2025-03-20T07:31:45.261753455Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:31:45 minikube dockerd[960]: time="2025-03-20T07:31:45.263886552Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:32:22 minikube dockerd[960]: time="2025-03-20T07:32:22.342297347Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:32:22 minikube dockerd[960]: time="2025-03-20T07:32:22.343117181Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:35:12 minikube dockerd[960]: time="2025-03-20T07:35:11.888904439Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:35:12 minikube dockerd[960]: time="2025-03-20T07:35:12.280773886Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:35:18 minikube dockerd[960]: time="2025-03-20T07:35:18.725882249Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:35:18 minikube dockerd[960]: time="2025-03-20T07:35:18.726313960Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:40:03 minikube dockerd[960]: time="2025-03-20T07:40:03.123658955Z" level=info msg="ignoring event" container=bc4260f5304aa176c5ee076362668c232d50f56b5853066f704348264f775e1a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 20 07:40:22 minikube dockerd[960]: time="2025-03-20T07:40:22.341013157Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:40:22 minikube dockerd[960]: time="2025-03-20T07:40:22.342047897Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Mar 20 07:40:26 minikube dockerd[960]: time="2025-03-20T07:40:26.374043620Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Mar 20 07:40:26 minikube dockerd[960]: time="2025-03-20T07:40:26.374125375Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"

* 
* ==> container status <==
* time="2025-03-20T07:43:39Z" level=fatal msg="connect: connect endpoint 'unix:///var/run/cri-dockerd.sock', make sure you are running as root and the endpoint has been started: context deadline exceeded"
CONTAINER ID   IMAGE                       COMMAND                  CREATED          STATUS                       PORTS     NAMES
41028b0f7f94   6e38f40d628d                "/storage-provisioner"   2 minutes ago    Up 2 minutes                           k8s_storage-provisioner_storage-provisioner_kube-system_39e8638e-d6a7-4c78-ac3e-32f6b14618bd_4
bc4260f5304a   6e38f40d628d                "/storage-provisioner"   12 minutes ago   Exited (255) 3 minutes ago             k8s_storage-provisioner_storage-provisioner_kube-system_39e8638e-d6a7-4c78-ac3e-32f6b14618bd_3
7c889692492f   registry.k8s.io/pause:3.9   "/pause"                 16 minutes ago   Up 16 minutes                          k8s_POD_combined-service-6745b8c7d-x8qs7_default_3783f1af-7cbd-4bab-9454-70a8aa0f2964_1
eb8d89d41059   5185b96f0bec                "/coredns -conf /etc…"   16 minutes ago   Up 16 minutes                          k8s_coredns_coredns-787d4945fb-dq6fr_kube-system_4d3f3be4-d397-4811-b407-19c60172a565_0
70d2416f4279   92ed2bec97a6                "/usr/local/bin/kube…"   16 minutes ago   Up 16 minutes                          k8s_kube-proxy_kube-proxy-l856r_kube-system_34c84511-12c9-497d-8e30-c268f07ede30_0
9348db177175   registry.k8s.io/pause:3.9   "/pause"                 16 minutes ago   Up 16 minutes                          k8s_POD_coredns-787d4945fb-dq6fr_kube-system_4d3f3be4-d397-4811-b407-19c60172a565_0
1500978e0f85   registry.k8s.io/pause:3.9   "/pause"                 16 minutes ago   Up 16 minutes                          k8s_POD_kube-proxy-l856r_kube-system_34c84511-12c9-497d-8e30-c268f07ede30_0
e164983598cf   registry.k8s.io/pause:3.9   "/pause"                 16 minutes ago   Up 16 minutes                          k8s_POD_storage-provisioner_kube-system_39e8638e-d6a7-4c78-ac3e-32f6b14618bd_0
62fdc6a5bc1e   1d9b3cbae03c                "kube-apiserver --ad…"   17 minutes ago   Up 17 minutes                          k8s_kube-apiserver_kube-apiserver-minikube_kube-system_cdcbce216c62c4407ac9a51ac013e7d7_0
7a580f4ab632   ce8c2293ef09                "kube-controller-man…"   17 minutes ago   Up 17 minutes                          k8s_kube-controller-manager_kube-controller-manager-minikube_kube-system_466b9e73e627277a8c24637c2fa6442d_0
f84bf83ce720   fce326961ae2                "etcd --advertise-cl…"   17 minutes ago   Up 17 minutes                          k8s_etcd_etcd-minikube_kube-system_a121e106627e5c6efa9ba48006cc43bf_0
30743d0390af   5a7904736932                "kube-scheduler --au…"   17 minutes ago   Up 17 minutes                          k8s_kube-scheduler_kube-scheduler-minikube_kube-system_0818f4b1a57de9c3f9c82667e7fcc870_0
b513d58ca5a3   registry.k8s.io/pause:3.9   "/pause"                 17 minutes ago   Up 17 minutes                          k8s_POD_kube-scheduler-minikube_kube-system_0818f4b1a57de9c3f9c82667e7fcc870_0
194560139f51   registry.k8s.io/pause:3.9   "/pause"                 17 minutes ago   Up 17 minutes                          k8s_POD_kube-apiserver-minikube_kube-system_cdcbce216c62c4407ac9a51ac013e7d7_0
9a3a0d075eb3   registry.k8s.io/pause:3.9   "/pause"                 17 minutes ago   Up 17 minutes                          k8s_POD_kube-controller-manager-minikube_kube-system_466b9e73e627277a8c24637c2fa6442d_0
2018109a9669   registry.k8s.io/pause:3.9   "/pause"                 17 minutes ago   Up 17 minutes                          k8s_POD_etcd-minikube_kube-system_a121e106627e5c6efa9ba48006cc43bf_0

* 
* ==> coredns [eb8d89d41059] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = f869070685748660180df1b7a47d58cdafcf2f368266578c062d1151dc2c900964aecc5975e8882e6de6fdfb6460463e30ebfaad2ec8f0c3c6436f80225b3b5b
CoreDNS-1.9.3
linux/amd64, go1.18.2, 45b0a11
[INFO] 127.0.0.1:56405 - 49178 "HINFO IN 523704447128706606.1734647521372537615. udp 56 false 512" NXDOMAIN qr,rd,ra 56 0.410570166s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.109429074s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.305991296s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.006706646s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.593680683s
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.002199395s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.307219851s
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": dial tcp :8080: i/o timeout (Client.Timeout exceeded while awaiting headers)
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.08051778s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.295827615s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.064766064s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.256665653s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.828902828s
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.090829168s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.01589312s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.267940556s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.114195876s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.397413286s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.500721037s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=08896fd1dc362c097c925146c4a0d0dac715ace0
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2025_03_20T14_26_35_0700
                    minikube.k8s.io/version=v1.30.1
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Thu, 20 Mar 2025 07:26:32 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Thu, 20 Mar 2025 07:43:39 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Thu, 20 Mar 2025 07:40:10 +0000   Thu, 20 Mar 2025 07:40:10 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Thu, 20 Mar 2025 07:40:10 +0000   Thu, 20 Mar 2025 07:40:10 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Thu, 20 Mar 2025 07:40:10 +0000   Thu, 20 Mar 2025 07:40:10 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Thu, 20 Mar 2025 07:40:10 +0000   Thu, 20 Mar 2025 07:40:10 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                8
  ephemeral-storage:  1055762868Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             2822936Ki
  pods:               110
Allocatable:
  cpu:                8
  ephemeral-storage:  1055762868Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             2822936Ki
  pods:               110
System Info:
  Machine ID:                 4be7b89512914632b7eb285a3ba7704a
  System UUID:                4be7b89512914632b7eb285a3ba7704a
  Boot ID:                    c30ecf9f-3370-4f23-b29f-a2c51b7ec055
  Kernel Version:             5.15.167.4-microsoft-standard-WSL2
  OS Image:                   Ubuntu 20.04.5 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://23.0.2
  Kubelet Version:            v1.26.3
  Kube-Proxy Version:         v1.26.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (8 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  default                     combined-service-6745b8c7d-x8qs7    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         16m
  kube-system                 coredns-787d4945fb-dq6fr            100m (1%!)(MISSING)     0 (0%!)(MISSING)      70Mi (2%!)(MISSING)        170Mi (6%!)(MISSING)     16m
  kube-system                 etcd-minikube                       100m (1%!)(MISSING)     0 (0%!)(MISSING)      100Mi (3%!)(MISSING)       0 (0%!)(MISSING)         17m
  kube-system                 kube-apiserver-minikube             250m (3%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17m
  kube-system                 kube-controller-manager-minikube    200m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17m
  kube-system                 kube-proxy-l856r                    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         16m
  kube-system                 kube-scheduler-minikube             100m (1%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17m
  kube-system                 storage-provisioner                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                750m (9%!)(MISSING)   0 (0%!)(MISSING)
  memory             170Mi (6%!)(MISSING)  170Mi (6%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                  From             Message
  ----    ------                   ----                 ----             -------
  Normal  Starting                 16m                  kube-proxy       
  Normal  NodeAllocatableEnforced  17m                  kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  17m (x5 over 17m)    kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    17m (x4 over 17m)    kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     17m (x4 over 17m)    kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  Starting                 17m                  kubelet          Starting kubelet.
  Normal  NodeNotReady             17m                  kubelet          Node minikube status is now: NodeNotReady
  Normal  NodeAllocatableEnforced  17m                  kubelet          Updated Node Allocatable limit across pods
  Normal  RegisteredNode           16m                  node-controller  Node minikube event: Registered Node minikube in Controller
  Normal  NodeNotReady             3m58s                node-controller  Node minikube status is now: NodeNotReady
  Normal  NodeHasSufficientMemory  3m34s (x2 over 17m)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    3m34s (x2 over 17m)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     3m34s (x2 over 17m)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeReady                3m34s (x2 over 16m)  kubelet          Node minikube status is now: NodeReady

* 
* ==> dmesg <==
* [Mar20 06:12] PCI: Fatal: No config space access function found
[  +0.011153] PCI: System does not support PCI
[  +0.077322] kvm: already loaded the other module
[  +1.179173] FS-Cache: Duplicate cookie detected
[  +0.000390] FS-Cache: O-cookie c=00000006 [p=00000002 fl=222 nc=0 na=1]
[  +0.000335] FS-Cache: O-cookie d=00000000b6585202{9P.session} n=00000000af20ea40
[  +0.000632] FS-Cache: O-key=[10] '34323934393337343233'
[  +0.000352] FS-Cache: N-cookie c=00000007 [p=00000002 fl=2 nc=0 na=1]
[  +0.000416] FS-Cache: N-cookie d=00000000b6585202{9P.session} n=0000000038d83efd
[  +0.000495] FS-Cache: N-key=[10] '34323934393337343233'
[  +0.647484] FS-Cache: Duplicate cookie detected
[  +0.000456] FS-Cache: O-cookie c=0000000b [p=00000002 fl=222 nc=0 na=1]
[  +0.000258] FS-Cache: O-cookie d=00000000b6585202{9P.session} n=000000002f539d08
[  +0.000465] FS-Cache: O-key=[10] '34323934393337343838'
[  +0.000642] FS-Cache: N-cookie c=0000000c [p=00000002 fl=2 nc=0 na=1]
[  +0.000567] FS-Cache: N-cookie d=00000000b6585202{9P.session} n=00000000e93f6004
[  +0.000396] FS-Cache: N-key=[10] '34323934393337343838'
[  +0.133111] WSL (1 - init(docker-desktop)) ERROR: ConfigApplyWindowsLibPath:2542: open /etc/ld.so.conf.d/ld.wsl.conf failed 2
[  +0.020761] FS-Cache: Duplicate cookie detected
[  +0.001714] FS-Cache: O-cookie c=0000000f [p=00000002 fl=222 nc=0 na=1]
[  +0.000624] FS-Cache: O-cookie d=00000000b6585202{9P.session} n=0000000090f349d4
[  +0.000644] FS-Cache: O-key=[10] '34323934393337353033'
[  +0.000635] FS-Cache: N-cookie c=00000010 [p=00000002 fl=2 nc=0 na=1]
[  +0.001643] FS-Cache: N-cookie d=00000000b6585202{9P.session} n=000000008d8bdee1
[  +0.000724] FS-Cache: N-key=[10] '34323934393337353033'
[  +0.004750] WSL (1 - init(docker-desktop)) WARNING: /usr/share/zoneinfo/Asia/Jakarta not found. Is the tzdata package installed?
[  +0.190559] misc dxg: dxgk: dxgkio_is_feature_enabled: Ioctl failed: -22
[  +0.009570] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000554] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.000556] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -22
[  +0.001586] misc dxg: dxgk: dxgkio_query_adapter_info: Ioctl failed: -2
[  +3.102133] netlink: 'init': attribute type 4 has an invalid length.
[  +0.893196] WSL (152) ERROR: CheckConnection: getaddrinfo() failed: -5
[Mar20 06:21] WSL (152) ERROR: CheckConnection: getaddrinfo() failed: -5
[Mar20 06:25] WSL (152) ERROR: CheckConnection: getaddrinfo() failed: -5
[Mar20 06:42] WSL (152) ERROR: CheckConnection: getaddrinfo() failed: -3
[  +5.002177] WSL (152) ERROR: CheckConnection: getaddrinfo() failed: -3
[Mar20 06:43] WSL (152) ERROR: CheckConnection: getaddrinfo() failed: -3
[  +5.005952] WSL (152) ERROR: CheckConnection: getaddrinfo() failed: -3
[Mar20 06:44] WSL (152) ERROR: CheckConnection: connect() failed: 101
[Mar20 07:29] hrtimer: interrupt took 43759313 ns

* 
* ==> etcd [f84bf83ce720] <==
* {"level":"info","ts":"2025-03-20T07:39:37.413Z","caller":"traceutil/trace.go:171","msg":"trace[94753468] linearizableReadLoop","detail":"{readStateIndex:1052; appliedIndex:1052; }","duration":"195.467395ms","start":"2025-03-20T07:39:37.214Z","end":"2025-03-20T07:39:37.409Z","steps":["trace[94753468] 'read index received'  (duration: 3.423409ms)","trace[94753468] 'applied index is now lower than readState.Index'  (duration: 191.95928ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:37.426Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"203.443251ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/csidrivers/\" range_end:\"/registry/csidrivers0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2025-03-20T07:39:37.427Z","caller":"traceutil/trace.go:171","msg":"trace[1491188826] range","detail":"{range_begin:/registry/csidrivers/; range_end:/registry/csidrivers0; response_count:0; response_revision:890; }","duration":"211.546016ms","start":"2025-03-20T07:39:37.215Z","end":"2025-03-20T07:39:37.427Z","steps":["trace[1491188826] 'agreement among raft nodes before linearized reading'  (duration: 202.323804ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-20T07:39:37.529Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"318.705776ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/prioritylevelconfigurations/\" range_end:\"/registry/prioritylevelconfigurations0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2025-03-20T07:39:37.530Z","caller":"traceutil/trace.go:171","msg":"trace[2055262562] range","detail":"{range_begin:/registry/prioritylevelconfigurations/; range_end:/registry/prioritylevelconfigurations0; response_count:0; response_revision:890; }","duration":"318.917246ms","start":"2025-03-20T07:39:37.210Z","end":"2025-03-20T07:39:37.529Z","steps":["trace[2055262562] 'agreement among raft nodes before linearized reading'  (duration: 205.714152ms)","trace[2055262562] 'count revisions from in-memory index tree'  (duration: 112.653744ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:37.598Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"283.740615ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/statefulsets/\" range_end:\"/registry/statefulsets0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2025-03-20T07:39:37.598Z","caller":"traceutil/trace.go:171","msg":"trace[859464744] range","detail":"{range_begin:/registry/statefulsets/; range_end:/registry/statefulsets0; response_count:0; response_revision:890; }","duration":"283.930804ms","start":"2025-03-20T07:39:37.314Z","end":"2025-03-20T07:39:37.598Z","steps":["trace[859464744] 'agreement among raft nodes before linearized reading'  (duration: 283.599913ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-20T07:39:37.616Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:37.204Z","time spent":"411.511306ms","remote":"127.0.0.1:57578","response type":"/etcdserverpb.KV/Range","request count":0,"request size":48,"response count":0,"response size":29,"request content":"key:\"/registry/csidrivers/\" range_end:\"/registry/csidrivers0\" count_only:true "}
{"level":"warn","ts":"2025-03-20T07:39:37.617Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:37.117Z","time spent":"413.029214ms","remote":"127.0.0.1:57608","response type":"/etcdserverpb.KV/Range","request count":0,"request size":82,"response count":8,"response size":31,"request content":"key:\"/registry/prioritylevelconfigurations/\" range_end:\"/registry/prioritylevelconfigurations0\" count_only:true "}
{"level":"warn","ts":"2025-03-20T07:39:39.801Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"107.785622ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/namespaces/default\" ","response":"range_response_count:1 size:341"}
{"level":"info","ts":"2025-03-20T07:39:39.814Z","caller":"traceutil/trace.go:171","msg":"trace[475266435] range","detail":"{range_begin:/registry/namespaces/default; range_end:; response_count:1; response_revision:890; }","duration":"180.697806ms","start":"2025-03-20T07:39:39.623Z","end":"2025-03-20T07:39:39.803Z","steps":["trace[475266435] 'agreement among raft nodes before linearized reading'  (duration: 77.029003ms)","trace[475266435] 'range keys from bolt db'  (duration: 26.017001ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:41.558Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"692.021427ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128036021151216311 > lease_revoke:<id:70cc95b2724c32a7>","response":"size:29"}
{"level":"info","ts":"2025-03-20T07:39:41.564Z","caller":"traceutil/trace.go:171","msg":"trace[1416884171] linearizableReadLoop","detail":"{readStateIndex:1053; appliedIndex:1052; }","duration":"1.048119233s","start":"2025-03-20T07:39:40.511Z","end":"2025-03-20T07:39:41.559Z","steps":["trace[1416884171] 'read index received'  (duration: 207.367094ms)","trace[1416884171] 'applied index is now lower than readState.Index'  (duration: 840.748422ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:41.706Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"1.194087039s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/poddisruptionbudgets/\" range_end:\"/registry/poddisruptionbudgets0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2025-03-20T07:39:41.711Z","caller":"traceutil/trace.go:171","msg":"trace[1659314095] range","detail":"{range_begin:/registry/poddisruptionbudgets/; range_end:/registry/poddisruptionbudgets0; response_count:0; response_revision:891; }","duration":"1.194866197s","start":"2025-03-20T07:39:40.511Z","end":"2025-03-20T07:39:41.706Z","steps":["trace[1659314095] 'agreement among raft nodes before linearized reading'  (duration: 1.049440859s)","trace[1659314095] 'count revisions from in-memory index tree'  (duration: 138.655753ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:41.713Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:40.511Z","time spent":"1.200331688s","remote":"127.0.0.1:57464","response type":"/etcdserverpb.KV/Range","request count":0,"request size":68,"response count":0,"response size":29,"request content":"key:\"/registry/poddisruptionbudgets/\" range_end:\"/registry/poddisruptionbudgets0\" count_only:true "}
{"level":"info","ts":"2025-03-20T07:39:42.913Z","caller":"traceutil/trace.go:171","msg":"trace[1393087388] transaction","detail":"{read_only:false; response_revision:892; number_of_response:1; }","duration":"162.830107ms","start":"2025-03-20T07:39:42.747Z","end":"2025-03-20T07:39:42.910Z","steps":["trace[1393087388] 'process raft request'  (duration: 61.550862ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-20T07:39:43.508Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"170.687536ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/rolebindings/\" range_end:\"/registry/rolebindings0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2025-03-20T07:39:43.509Z","caller":"traceutil/trace.go:171","msg":"trace[1386112789] range","detail":"{range_begin:/registry/rolebindings/; range_end:/registry/rolebindings0; response_count:0; response_revision:892; }","duration":"171.61399ms","start":"2025-03-20T07:39:43.337Z","end":"2025-03-20T07:39:43.509Z","steps":["trace[1386112789] 'count revisions from in-memory index tree'  (duration: 168.886022ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-20T07:39:44.028Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"165.766279ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128036021151216315 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/minions/minikube\" mod_revision:821 > success:<request_put:<key:\"/registry/minions/minikube\" value_size:4789 >> failure:<request_range:<key:\"/registry/minions/minikube\" > >>","response":"size:16"}
{"level":"info","ts":"2025-03-20T07:39:44.143Z","caller":"traceutil/trace.go:171","msg":"trace[761287062] transaction","detail":"{read_only:false; response_revision:893; number_of_response:1; }","duration":"630.540605ms","start":"2025-03-20T07:39:43.513Z","end":"2025-03-20T07:39:44.143Z","steps":["trace[761287062] 'process raft request'  (duration: 23.541196ms)","trace[761287062] 'compare'  (duration: 80.323083ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:44.144Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:43.512Z","time spent":"630.948827ms","remote":"127.0.0.1:57260","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":4823,"response count":0,"response size":40,"request content":"compare:<target:MOD key:\"/registry/minions/minikube\" mod_revision:821 > success:<request_put:<key:\"/registry/minions/minikube\" value_size:4789 >> failure:<request_range:<key:\"/registry/minions/minikube\" > >"}
{"level":"info","ts":"2025-03-20T07:39:45.237Z","caller":"traceutil/trace.go:171","msg":"trace[1437791840] linearizableReadLoop","detail":"{readStateIndex:1055; appliedIndex:1055; }","duration":"158.488019ms","start":"2025-03-20T07:39:45.074Z","end":"2025-03-20T07:39:45.233Z","steps":["trace[1437791840] 'read index received'  (duration: 158.477354ms)","trace[1437791840] 'applied index is now lower than readState.Index'  (duration: 8.98µs)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:45.720Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"710.091459ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/specs/default/kubernetes\" ","response":"range_response_count:1 size:704"}
{"level":"info","ts":"2025-03-20T07:39:45.721Z","caller":"traceutil/trace.go:171","msg":"trace[2062643742] range","detail":"{range_begin:/registry/services/specs/default/kubernetes; range_end:; response_count:1; response_revision:893; }","duration":"711.276827ms","start":"2025-03-20T07:39:45.009Z","end":"2025-03-20T07:39:45.720Z","steps":["trace[2062643742] 'agreement among raft nodes before linearized reading'  (duration: 240.760146ms)","trace[2062643742] 'range keys from in-memory index tree'  (duration: 254.765739ms)","trace[2062643742] 'range keys from bolt db'  (duration: 210.270362ms)"],"step_count":3}
{"level":"warn","ts":"2025-03-20T07:39:45.722Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:45.008Z","time spent":"713.28976ms","remote":"127.0.0.1:57324","response type":"/etcdserverpb.KV/Range","request count":0,"request size":45,"response count":1,"response size":728,"request content":"key:\"/registry/services/specs/default/kubernetes\" "}
{"level":"warn","ts":"2025-03-20T07:39:48.319Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"1.304258688s","expected-duration":"100ms","prefix":"","request":"header:<ID:8128036021151216319 username:\"kube-apiserver-etcd-client\" auth_revision:1 > lease_grant:<ttl:15-second id:70cc95b2724c32be>","response":"size:41"}
{"level":"warn","ts":"2025-03-20T07:39:48.325Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:46.512Z","time spent":"1.812467292s","remote":"127.0.0.1:57190","response type":"/etcdserverpb.Lease/LeaseGrant","request count":-1,"request size":-1,"response count":-1,"response size":-1,"request content":""}
{"level":"info","ts":"2025-03-20T07:39:49.022Z","caller":"traceutil/trace.go:171","msg":"trace[988407520] transaction","detail":"{read_only:false; response_revision:894; number_of_response:1; }","duration":"216.607763ms","start":"2025-03-20T07:39:48.804Z","end":"2025-03-20T07:39:49.021Z","steps":["trace[988407520] 'process raft request'  (duration: 209.834471ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-20T07:39:51.456Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"386.361692ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:420"}
{"level":"info","ts":"2025-03-20T07:39:51.552Z","caller":"traceutil/trace.go:171","msg":"trace[1400588608] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:894; }","duration":"483.22175ms","start":"2025-03-20T07:39:50.974Z","end":"2025-03-20T07:39:51.458Z","steps":["trace[1400588608] 'range keys from in-memory index tree'  (duration: 183.970616ms)","trace[1400588608] 'range keys from bolt db'  (duration: 198.942051ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:51.555Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:50.974Z","time spent":"580.870382ms","remote":"127.0.0.1:57250","response type":"/etcdserverpb.KV/Range","request count":0,"request size":49,"response count":1,"response size":444,"request content":"key:\"/registry/services/endpoints/default/kubernetes\" "}
{"level":"warn","ts":"2025-03-20T07:39:52.153Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"203.85619ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128036021151216323 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/default/minikube.182e72da0271c36c\" mod_revision:0 > success:<request_put:<key:\"/registry/events/default/minikube.182e72da0271c36c\" value_size:520 lease:8128036021151216298 >> failure:<>>","response":"size:16"}
{"level":"info","ts":"2025-03-20T07:39:52.154Z","caller":"traceutil/trace.go:171","msg":"trace[1102832504] transaction","detail":"{read_only:false; response_revision:895; number_of_response:1; }","duration":"694.297393ms","start":"2025-03-20T07:39:51.459Z","end":"2025-03-20T07:39:52.153Z","steps":["trace[1102832504] 'process raft request'  (duration: 391.011265ms)"],"step_count":1}
{"level":"info","ts":"2025-03-20T07:39:52.153Z","caller":"traceutil/trace.go:171","msg":"trace[854206449] linearizableReadLoop","detail":"{readStateIndex:1058; appliedIndex:1057; }","duration":"292.239592ms","start":"2025-03-20T07:39:51.861Z","end":"2025-03-20T07:39:52.153Z","steps":["trace[854206449] 'read index received'  (duration: 118.58µs)","trace[854206449] 'applied index is now lower than readState.Index'  (duration: 292.119064ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:52.250Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:51.453Z","time spent":"701.453618ms","remote":"127.0.0.1:57196","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":588,"response count":0,"response size":40,"request content":"compare:<target:MOD key:\"/registry/events/default/minikube.182e72da0271c36c\" mod_revision:0 > success:<request_put:<key:\"/registry/events/default/minikube.182e72da0271c36c\" value_size:520 lease:8128036021151216298 >> failure:<>"}
{"level":"warn","ts":"2025-03-20T07:39:52.264Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"403.041834ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/masterleases/\" range_end:\"/registry/masterleases0\" ","response":"range_response_count:1 size:131"}
{"level":"info","ts":"2025-03-20T07:39:52.265Z","caller":"traceutil/trace.go:171","msg":"trace[2016524200] range","detail":"{range_begin:/registry/masterleases/; range_end:/registry/masterleases0; response_count:1; response_revision:895; }","duration":"403.464085ms","start":"2025-03-20T07:39:51.861Z","end":"2025-03-20T07:39:52.264Z","steps":["trace[2016524200] 'agreement among raft nodes before linearized reading'  (duration: 292.740548ms)","trace[2016524200] 'range keys from in-memory index tree'  (duration: 108.320369ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-20T07:39:52.265Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:51.861Z","time spent":"404.327513ms","remote":"127.0.0.1:57190","response type":"/etcdserverpb.KV/Range","request count":0,"request size":50,"response count":1,"response size":155,"request content":"key:\"/registry/masterleases/\" range_end:\"/registry/masterleases0\" "}
{"level":"info","ts":"2025-03-20T07:39:52.651Z","caller":"traceutil/trace.go:171","msg":"trace[1512177589] transaction","detail":"{read_only:false; response_revision:896; number_of_response:1; }","duration":"177.322825ms","start":"2025-03-20T07:39:52.473Z","end":"2025-03-20T07:39:52.651Z","steps":["trace[1512177589] 'process raft request'  (duration: 176.277894ms)"],"step_count":1}
{"level":"info","ts":"2025-03-20T07:39:54.660Z","caller":"traceutil/trace.go:171","msg":"trace[1711152412] transaction","detail":"{read_only:false; response_revision:898; number_of_response:1; }","duration":"794.38577ms","start":"2025-03-20T07:39:53.465Z","end":"2025-03-20T07:39:54.259Z","steps":[],"step_count":0}
{"level":"warn","ts":"2025-03-20T07:39:54.951Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-20T07:39:53.465Z","time spent":"1.195817483s","remote":"127.0.0.1:57190","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":116,"response count":0,"response size":40,"request content":"compare:<target:MOD key:\"/registry/masterleases/192.168.49.2\" mod_revision:894 > success:<request_put:<key:\"/registry/masterleases/192.168.49.2\" value_size:65 lease:8128036021151216331 >> failure:<request_range:<key:\"/registry/masterleases/192.168.49.2\" > >"}
{"level":"info","ts":"2025-03-20T07:39:54.968Z","caller":"traceutil/trace.go:171","msg":"trace[1374351873] transaction","detail":"{read_only:false; response_revision:899; number_of_response:1; }","duration":"105.003986ms","start":"2025-03-20T07:39:54.862Z","end":"2025-03-20T07:39:54.967Z","steps":["trace[1374351873] 'process raft request'  (duration: 92.144739ms)","trace[1374351873] 'compare'  (duration: 11.386066ms)"],"step_count":2}
{"level":"info","ts":"2025-03-20T07:39:55.558Z","caller":"traceutil/trace.go:171","msg":"trace[1378203747] transaction","detail":"{read_only:false; response_revision:901; number_of_response:1; }","duration":"292.720806ms","start":"2025-03-20T07:39:55.265Z","end":"2025-03-20T07:39:55.558Z","steps":["trace[1378203747] 'process raft request'  (duration: 194.566284ms)","trace[1378203747] 'compare'  (duration: 94.601324ms)"],"step_count":2}
{"level":"info","ts":"2025-03-20T07:39:56.558Z","caller":"traceutil/trace.go:171","msg":"trace[545059389] transaction","detail":"{read_only:false; response_revision:903; number_of_response:1; }","duration":"190.623602ms","start":"2025-03-20T07:39:56.368Z","end":"2025-03-20T07:39:56.558Z","steps":["trace[545059389] 'process raft request'  (duration: 187.076736ms)"],"step_count":1}
{"level":"info","ts":"2025-03-20T07:39:58.357Z","caller":"traceutil/trace.go:171","msg":"trace[393446809] transaction","detail":"{read_only:false; response_revision:905; number_of_response:1; }","duration":"189.135647ms","start":"2025-03-20T07:39:58.167Z","end":"2025-03-20T07:39:58.356Z","steps":["trace[393446809] 'process raft request'  (duration: 181.476256ms)"],"step_count":1}
{"level":"info","ts":"2025-03-20T07:39:59.560Z","caller":"traceutil/trace.go:171","msg":"trace[902123194] transaction","detail":"{read_only:false; response_revision:909; number_of_response:1; }","duration":"106.188927ms","start":"2025-03-20T07:39:59.454Z","end":"2025-03-20T07:39:59.560Z","steps":["trace[902123194] 'process raft request'  (duration: 95.427945ms)"],"step_count":1}
{"level":"info","ts":"2025-03-20T07:40:00.954Z","caller":"traceutil/trace.go:171","msg":"trace[1429499056] transaction","detail":"{read_only:false; response_revision:912; number_of_response:1; }","duration":"105.243053ms","start":"2025-03-20T07:40:00.849Z","end":"2025-03-20T07:40:00.954Z","steps":["trace[1429499056] 'process raft request'  (duration: 20.017354ms)","trace[1429499056] 'compare'  (duration: 83.971785ms)"],"step_count":2}
{"level":"info","ts":"2025-03-20T07:40:01.060Z","caller":"traceutil/trace.go:171","msg":"trace[317505211] transaction","detail":"{read_only:false; response_revision:913; number_of_response:1; }","duration":"103.403036ms","start":"2025-03-20T07:40:00.957Z","end":"2025-03-20T07:40:01.060Z","steps":["trace[317505211] 'process raft request'  (duration: 92.553469ms)"],"step_count":1}
{"level":"info","ts":"2025-03-20T07:40:01.274Z","caller":"traceutil/trace.go:171","msg":"trace[1933175729] transaction","detail":"{read_only:false; response_revision:915; number_of_response:1; }","duration":"107.922077ms","start":"2025-03-20T07:40:01.166Z","end":"2025-03-20T07:40:01.274Z","steps":["trace[1933175729] 'process raft request'  (duration: 88.224792ms)","trace[1933175729] 'compare'  (duration: 18.390744ms)"],"step_count":2}
{"level":"info","ts":"2025-03-20T07:40:02.067Z","caller":"traceutil/trace.go:171","msg":"trace[1877047374] transaction","detail":"{read_only:false; response_revision:921; number_of_response:1; }","duration":"104.201671ms","start":"2025-03-20T07:40:01.963Z","end":"2025-03-20T07:40:02.067Z","steps":["trace[1877047374] 'process raft request'  (duration: 85.785533ms)","trace[1877047374] 'compare'  (duration: 16.772317ms)"],"step_count":2}
{"level":"info","ts":"2025-03-20T07:40:02.149Z","caller":"traceutil/trace.go:171","msg":"trace[1995512451] transaction","detail":"{read_only:false; response_revision:922; number_of_response:1; }","duration":"178.650757ms","start":"2025-03-20T07:40:01.970Z","end":"2025-03-20T07:40:02.149Z","steps":["trace[1995512451] 'process raft request'  (duration: 178.463453ms)"],"step_count":1}
{"level":"info","ts":"2025-03-20T07:41:30.874Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":798}
{"level":"info","ts":"2025-03-20T07:41:30.917Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":798,"took":"30.889531ms","hash":1879435759}
{"level":"info","ts":"2025-03-20T07:41:30.918Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1879435759,"revision":798,"compact-revision":578}
{"level":"info","ts":"2025-03-20T07:43:32.689Z","caller":"traceutil/trace.go:171","msg":"trace[1463510597] transaction","detail":"{read_only:false; response_revision:1099; number_of_response:1; }","duration":"154.745037ms","start":"2025-03-20T07:43:32.524Z","end":"2025-03-20T07:43:32.678Z","steps":["trace[1463510597] 'process raft request'  (duration: 154.592219ms)"],"step_count":1}
{"level":"info","ts":"2025-03-20T07:43:40.195Z","caller":"traceutil/trace.go:171","msg":"trace[258660269] transaction","detail":"{read_only:false; response_revision:1103; number_of_response:1; }","duration":"104.994659ms","start":"2025-03-20T07:43:40.090Z","end":"2025-03-20T07:43:40.195Z","steps":["trace[258660269] 'process raft request'  (duration: 98.732009ms)"],"step_count":1}
{"level":"info","ts":"2025-03-20T07:43:40.191Z","caller":"traceutil/trace.go:171","msg":"trace[638059675] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:1103; }","duration":"188.345766ms","start":"2025-03-20T07:43:40.001Z","end":"2025-03-20T07:43:40.189Z","steps":["trace[638059675] 'agreement among raft nodes before linearized reading'  (duration: 188.283726ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-20T07:43:44.316Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"122.512688ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/\" range_end:\"/registry/events0\" limit:500 ","response":"range_response_count:76 size:52565"}
{"level":"info","ts":"2025-03-20T07:43:44.321Z","caller":"traceutil/trace.go:171","msg":"trace[411439850] range","detail":"{range_begin:/registry/events/; range_end:/registry/events0; response_count:76; response_revision:1107; }","duration":"151.913063ms","start":"2025-03-20T07:43:44.169Z","end":"2025-03-20T07:43:44.321Z","steps":["trace[411439850] 'range keys from bolt db'  (duration: 121.328539ms)"],"step_count":1}

* 
* ==> kernel <==
*  07:43:45 up  1:31,  0 users,  load average: 0.60, 3.39, 3.31
Linux minikube 5.15.167.4-microsoft-standard-WSL2 #1 SMP Tue Nov 5 00:21:55 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 20.04.5 LTS"

* 
* ==> kube-apiserver [62fdc6a5bc1e] <==
* Trace[1569709714]: ---"Transaction prepared" 189ms (07:39:53.454)
Trace[1569709714]: ---"Txn call completed" 1617ms (07:39:55.072)
Trace[1569709714]: [1.811223428s] [1.811223428s] END
I0320 07:39:55.154965       1 trace.go:219] Trace[1813616256]: "Create" accept:application/vnd.kubernetes.protobuf, */*,audit-id:caf7d662-5989-412d-86d9-b8f1a54ad0f0,client:192.168.49.2,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events,user-agent:kube-controller-manager/v1.26.3 (linux/amd64) kubernetes/9e64410/system:serviceaccount:kube-system:node-controller,verb:POST (20-Mar-2025 07:39:53.754) (total time: 1400ms):
Trace[1813616256]: ["Create etcd3" audit-id:caf7d662-5989-412d-86d9-b8f1a54ad0f0,key:/events/kube-system/kube-apiserver-minikube.182e72dbade2d6a3,type:*core.Event,resource:events 1282ms (07:39:53.872)
Trace[1813616256]:  ---"Txn call succeeded" 1278ms (07:39:55.150)]
Trace[1813616256]: [1.400243291s] [1.400243291s] END
I0320 07:39:55.556153       1 trace.go:219] Trace[39043107]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:8614559c-3c89-44ff-a969-2325500799d5,client:::1,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-apiserver-kcdegeihzlqbkh65rirrc5zxju,user-agent:kube-apiserver/v1.26.3 (linux/amd64) kubernetes/9e64410,verb:PUT (20-Mar-2025 07:39:54.664) (total time: 889ms):
Trace[39043107]: ["GuaranteedUpdate etcd3" audit-id:8614559c-3c89-44ff-a969-2325500799d5,key:/leases/kube-system/kube-apiserver-kcdegeihzlqbkh65rirrc5zxju,type:*coordination.Lease,resource:leases.coordination.k8s.io 885ms (07:39:54.669)
Trace[39043107]:  ---"About to Encode" 399ms (07:39:55.069)
Trace[39043107]:  ---"Txn call completed" 302ms (07:39:55.372)]
Trace[39043107]: ---"Writing http response done" 182ms (07:39:55.554)
Trace[39043107]: [889.97996ms] [889.97996ms] END
I0320 07:39:55.571056       1 trace.go:219] Trace[755745621]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:e80b7f33-333b-4300-a6c4-9e0272666e22,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/kube-system/pods/etcd-minikube/status,user-agent:kube-controller-manager/v1.26.3 (linux/amd64) kubernetes/9e64410/system:serviceaccount:kube-system:node-controller,verb:PUT (20-Mar-2025 07:39:53.877) (total time: 1692ms):
Trace[755745621]: ---"limitedReadBody succeeded" len:5091 71ms (07:39:53.949)
Trace[755745621]: ["GuaranteedUpdate etcd3" audit-id:e80b7f33-333b-4300-a6c4-9e0272666e22,key:/pods/kube-system/etcd-minikube,type:*core.Pod,resource:pods 1601ms (07:39:53.968)
Trace[755745621]:  ---"About to Encode" 1193ms (07:39:55.162)
Trace[755745621]:  ---"Txn call completed" 394ms (07:39:55.561)]
Trace[755745621]: [1.692684223s] [1.692684223s] END
I0320 07:39:56.657073       1 trace.go:219] Trace[1860978259]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:686a54f0-c0a3-4675-b6fe-f482c08f41a8,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/kube-system/pods/kube-controller-manager-minikube/status,user-agent:kube-controller-manager/v1.26.3 (linux/amd64) kubernetes/9e64410/system:serviceaccount:kube-system:node-controller,verb:PUT (20-Mar-2025 07:39:55.777) (total time: 876ms):
Trace[1860978259]: ---"limitedReadBody succeeded" len:6737 177ms (07:39:55.955)
Trace[1860978259]: ["GuaranteedUpdate etcd3" audit-id:686a54f0-c0a3-4675-b6fe-f482c08f41a8,key:/pods/kube-system/kube-controller-manager-minikube,type:*core.Pod,resource:pods 694ms (07:39:55.962)
Trace[1860978259]:  ---"About to Encode" 400ms (07:39:56.363)
Trace[1860978259]:  ---"Txn call completed" 203ms (07:39:56.567)
Trace[1860978259]:  ---"decode succeeded" len:6865 81ms (07:39:56.649)]
Trace[1860978259]: [876.498304ms] [876.498304ms] END
I0320 07:39:58.461274       1 trace.go:219] Trace[2025457641]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:7e8e64bb-abb6-415f-8f91-a0af9ee77579,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/kube-system/pods/kube-scheduler-minikube/status,user-agent:kube-controller-manager/v1.26.3 (linux/amd64) kubernetes/9e64410/system:serviceaccount:kube-system:node-controller,verb:PUT (20-Mar-2025 07:39:56.763) (total time: 1697ms):
Trace[2025457641]: ["GuaranteedUpdate etcd3" audit-id:7e8e64bb-abb6-415f-8f91-a0af9ee77579,key:/pods/kube-system/kube-scheduler-minikube,type:*core.Pod,resource:pods 1510ms (07:39:56.950)
Trace[2025457641]:  ---"About to Encode" 1104ms (07:39:58.056)
Trace[2025457641]:  ---"Txn call completed" 306ms (07:39:58.362)
Trace[2025457641]:  ---"decode succeeded" len:4126 97ms (07:39:58.460)]
Trace[2025457641]: [1.697359443s] [1.697359443s] END
I0320 07:39:59.749436       1 trace.go:219] Trace[1188581646]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:a863df63-8692-42ca-8962-b68558f2cb11,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/kube-system/pods/kube-proxy-l856r/status,user-agent:kube-controller-manager/v1.26.3 (linux/amd64) kubernetes/9e64410/system:serviceaccount:kube-system:node-controller,verb:PUT (20-Mar-2025 07:39:59.152) (total time: 596ms):
Trace[1188581646]: ---"Writing http response done" 81ms (07:39:59.749)
Trace[1188581646]: [596.355969ms] [596.355969ms] END
I0320 07:40:00.765352       1 trace.go:219] Trace[366053154]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:92337fe8-9fad-4757-98d9-689bb00d9f29,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/kube-system/pods/coredns-787d4945fb-dq6fr/status,user-agent:kube-controller-manager/v1.26.3 (linux/amd64) kubernetes/9e64410/system:serviceaccount:kube-system:node-controller,verb:PUT (20-Mar-2025 07:39:59.855) (total time: 908ms):
Trace[366053154]: ["GuaranteedUpdate etcd3" audit-id:92337fe8-9fad-4757-98d9-689bb00d9f29,key:/pods/kube-system/coredns-787d4945fb-dq6fr,type:*core.Pod,resource:pods 894ms (07:39:59.870)
Trace[366053154]:  ---"initial value restored" 95ms (07:39:59.966)
Trace[366053154]:  ---"About to Encode" 691ms (07:40:00.657)
Trace[366053154]:  ---"Txn call completed" 103ms (07:40:00.762)]
Trace[366053154]: [908.861837ms] [908.861837ms] END
I0320 07:40:01.068447       1 trace.go:219] Trace[664938086]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:6041ef3f-4b53-4c81-b5e3-d20708d5b132,client:192.168.49.2,protocol:HTTP/2.0,resource:daemonsets,scope:resource,url:/apis/apps/v1/namespaces/kube-system/daemonsets/kube-proxy/status,user-agent:kube-controller-manager/v1.26.3 (linux/amd64) kubernetes/9e64410/system:serviceaccount:kube-system:daemon-set-controller,verb:PUT (20-Mar-2025 07:40:00.349) (total time: 718ms):
Trace[664938086]: ---"Conversion done" 99ms (07:40:00.451)
Trace[664938086]: ["GuaranteedUpdate etcd3" audit-id:6041ef3f-4b53-4c81-b5e3-d20708d5b132,key:/daemonsets/kube-system/kube-proxy,type:*apps.DaemonSet,resource:daemonsets.apps 611ms (07:40:00.457)
Trace[664938086]:  ---"About to Encode" 491ms (07:40:00.949)
Trace[664938086]:  ---"Txn call completed" 114ms (07:40:01.064)]
Trace[664938086]: [718.30706ms] [718.30706ms] END
I0320 07:40:02.157037       1 trace.go:219] Trace[2083261693]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:36ab6b12-dac0-4a1c-a0ca-0fee6821bff8,client:192.168.49.2,protocol:HTTP/2.0,resource:deployments,scope:resource,url:/apis/apps/v1/namespaces/kube-system/deployments/coredns/status,user-agent:kube-controller-manager/v1.26.3 (linux/amd64) kubernetes/9e64410/system:serviceaccount:kube-system:deployment-controller,verb:PUT (20-Mar-2025 07:40:01.567) (total time: 589ms):
Trace[2083261693]: ---"limitedReadBody succeeded" len:4059 84ms (07:40:01.652)
Trace[2083261693]: [589.324125ms] [589.324125ms] END
I0320 07:43:40.400265       1 trace.go:219] Trace[1606890215]: "Update" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:9c5fc822-90f5-46cb-ba5c-d2b8bd726634,client:192.168.49.2,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube,user-agent:kubelet/v1.26.3 (linux/amd64) kubernetes/9e64410,verb:PUT (20-Mar-2025 07:43:39.691) (total time: 521ms):
Trace[1606890215]: ["GuaranteedUpdate etcd3" audit-id:9c5fc822-90f5-46cb-ba5c-d2b8bd726634,key:/leases/kube-node-lease/minikube,type:*coordination.Lease,resource:leases.coordination.k8s.io 515ms (07:43:39.700)
Trace[1606890215]:  ---"initial value restored" 92ms (07:43:39.792)
Trace[1606890215]:  ---"About to Encode" 297ms (07:43:40.089)
Trace[1606890215]:  ---"Txn call completed" 121ms (07:43:40.211)]
Trace[1606890215]: [521.573674ms] [521.573674ms] END
I0320 07:43:44.635481       1 trace.go:219] Trace[191564852]: "List" accept:application/json, */*,audit-id:fd0f6433-8c3f-4a94-a2b4-989ec0d6b154,client:::1,protocol:HTTP/2.0,resource:events,scope:cluster,url:/api/v1/events,user-agent:kubectl/v1.26.3 (linux/amd64) kubernetes/9e64410,verb:LIST (20-Mar-2025 07:43:44.044) (total time: 588ms):
Trace[191564852]: ["List(recursive=true) etcd3" audit-id:fd0f6433-8c3f-4a94-a2b4-989ec0d6b154,key:/events,resourceVersion:,resourceVersionMatch:,limit:500,continue: 590ms (07:43:44.045)]
Trace[191564852]: ---"Writing http response done" count:2 56ms (07:43:44.633)
Trace[191564852]: [588.988115ms] [588.988115ms] END

* 
* ==> kube-controller-manager [7a580f4ab632] <==
* I0320 07:26:47.184704       1 shared_informer.go:280] Caches are synced for service account
I0320 07:26:47.186060       1 shared_informer.go:280] Caches are synced for deployment
I0320 07:26:47.190296       1 shared_informer.go:280] Caches are synced for stateful set
I0320 07:26:47.191318       1 shared_informer.go:280] Caches are synced for node
I0320 07:26:47.191354       1 range_allocator.go:167] Sending events to api server.
I0320 07:26:47.191367       1 range_allocator.go:171] Starting range CIDR allocator
I0320 07:26:47.191369       1 shared_informer.go:273] Waiting for caches to sync for cidrallocator
I0320 07:26:47.191374       1 shared_informer.go:280] Caches are synced for cidrallocator
I0320 07:26:47.199740       1 shared_informer.go:280] Caches are synced for expand
I0320 07:26:47.206407       1 shared_informer.go:280] Caches are synced for bootstrap_signer
I0320 07:26:47.206500       1 shared_informer.go:280] Caches are synced for ephemeral
I0320 07:26:47.206518       1 shared_informer.go:280] Caches are synced for TTL after finished
I0320 07:26:47.208030       1 shared_informer.go:280] Caches are synced for PV protection
I0320 07:26:47.208252       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kubelet-serving
I0320 07:26:47.208315       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kubelet-client
I0320 07:26:47.209406       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-legacy-unknown
I0320 07:26:47.209455       1 shared_informer.go:280] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0320 07:26:47.209476       1 shared_informer.go:280] Caches are synced for persistent volume
I0320 07:26:47.212786       1 shared_informer.go:280] Caches are synced for attach detach
I0320 07:26:47.213853       1 range_allocator.go:372] Set node minikube PodCIDR to [10.244.0.0/24]
I0320 07:26:47.215483       1 shared_informer.go:280] Caches are synced for endpoint_slice_mirroring
I0320 07:26:47.218945       1 shared_informer.go:280] Caches are synced for PVC protection
I0320 07:26:47.227557       1 shared_informer.go:280] Caches are synced for ReplicationController
I0320 07:26:47.227780       1 shared_informer.go:280] Caches are synced for certificate-csrapproving
I0320 07:26:47.232411       1 shared_informer.go:280] Caches are synced for disruption
I0320 07:26:47.233721       1 shared_informer.go:280] Caches are synced for daemon sets
I0320 07:26:47.233742       1 shared_informer.go:280] Caches are synced for endpoint_slice
I0320 07:26:47.234085       1 shared_informer.go:280] Caches are synced for endpoint
I0320 07:26:47.236386       1 shared_informer.go:280] Caches are synced for ReplicaSet
I0320 07:26:47.236525       1 shared_informer.go:280] Caches are synced for crt configmap
I0320 07:26:47.244170       1 shared_informer.go:280] Caches are synced for GC
I0320 07:26:47.246953       1 shared_informer.go:280] Caches are synced for taint
I0320 07:26:47.247121       1 node_lifecycle_controller.go:1438] Initializing eviction metric for zone: 
I0320 07:26:47.247293       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
W0320 07:26:47.247332       1 node_lifecycle_controller.go:1053] Missing timestamp for Node minikube. Assuming now as a timestamp.
I0320 07:26:47.247388       1 taint_manager.go:211] "Sending events to api server"
I0320 07:26:47.247393       1 node_lifecycle_controller.go:1254] Controller detected that zone  is now in state Normal.
I0320 07:26:47.247726       1 event.go:294] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0320 07:26:47.307320       1 shared_informer.go:280] Caches are synced for cronjob
I0320 07:26:47.439796       1 shared_informer.go:280] Caches are synced for resource quota
I0320 07:26:47.450603       1 shared_informer.go:280] Caches are synced for resource quota
I0320 07:26:47.505260       1 shared_informer.go:280] Caches are synced for HPA
I0320 07:26:47.762795       1 shared_informer.go:280] Caches are synced for garbage collector
I0320 07:26:47.825984       1 shared_informer.go:280] Caches are synced for garbage collector
I0320 07:26:47.826042       1 garbagecollector.go:163] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
I0320 07:26:47.850218       1 event.go:294] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-787d4945fb to 1"
I0320 07:26:48.147333       1 event.go:294] "Event occurred" object="kube-system/kube-proxy" fieldPath="" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-l856r"
I0320 07:26:48.238714       1 event.go:294] "Event occurred" object="kube-system/coredns-787d4945fb" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-787d4945fb-dq6fr"
I0320 07:27:22.647093       1 event.go:294] "Event occurred" object="default/combined-service" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set combined-service-6745b8c7d to 1"
I0320 07:27:22.669029       1 event.go:294] "Event occurred" object="default/combined-service-6745b8c7d" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: combined-service-6745b8c7d-x8qs7"
I0320 07:39:46.725204       1 event.go:294] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="NodeNotReady" message="Node minikube status is now: NodeNotReady"
I0320 07:39:53.758770       1 event.go:294] "Event occurred" object="kube-system/kube-apiserver-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0320 07:39:55.673579       1 event.go:294] "Event occurred" object="kube-system/etcd-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0320 07:39:56.752465       1 event.go:294] "Event occurred" object="kube-system/kube-controller-manager-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0320 07:39:58.567581       1 event.go:294] "Event occurred" object="kube-system/kube-scheduler-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0320 07:39:59.068640       1 event.go:294] "Event occurred" object="kube-system/storage-provisioner" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0320 07:39:59.759688       1 event.go:294] "Event occurred" object="kube-system/kube-proxy-l856r" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0320 07:40:00.772045       1 event.go:294] "Event occurred" object="kube-system/coredns-787d4945fb-dq6fr" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0320 07:40:00.955746       1 node_lifecycle_controller.go:1204] Controller detected that all Nodes are not-Ready. Entering master disruption mode.
I0320 07:40:10.969354       1 node_lifecycle_controller.go:1231] Controller detected that some Nodes are Ready. Exiting master disruption mode.

* 
* ==> kube-proxy [70d2416f4279] <==
* I0320 07:26:49.421591       1 proxier.go:242] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0320 07:26:49.423841       1 server.go:655] "Version info" version="v1.26.3"
I0320 07:26:49.423866       1 server.go:657] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0320 07:26:49.425761       1 config.go:317] "Starting service config controller"
I0320 07:26:49.426244       1 config.go:226] "Starting endpoint slice config controller"
I0320 07:26:49.426385       1 shared_informer.go:273] Waiting for caches to sync for endpoint slice config
I0320 07:26:49.426435       1 config.go:444] "Starting node config controller"
I0320 07:26:49.426468       1 shared_informer.go:273] Waiting for caches to sync for node config
I0320 07:26:49.426761       1 shared_informer.go:273] Waiting for caches to sync for service config
I0320 07:26:49.527050       1 shared_informer.go:280] Caches are synced for endpoint slice config
I0320 07:26:49.527075       1 shared_informer.go:280] Caches are synced for node config
I0320 07:26:49.529415       1 shared_informer.go:280] Caches are synced for service config
I0320 07:28:54.953183       1 trace.go:219] Trace[1798696982]: "iptables ChainExists" (20-Mar-2025 07:28:51.233) (total time: 3498ms):
Trace[1798696982]: [3.498579086s] [3.498579086s] END
I0320 07:28:55.038986       1 trace.go:219] Trace[1424531523]: "iptables ChainExists" (20-Mar-2025 07:28:50.260) (total time: 4278ms):
Trace[1424531523]: [4.278634112s] [4.278634112s] END
I0320 07:29:39.863888       1 trace.go:219] Trace[184998043]: "iptables ChainExists" (20-Mar-2025 07:29:25.071) (total time: 14712ms):
Trace[184998043]: [14.712873591s] [14.712873591s] END
I0320 07:29:39.894238       1 trace.go:219] Trace[1610039523]: "iptables ChainExists" (20-Mar-2025 07:29:23.402) (total time: 16491ms):
Trace[1610039523]: [16.491638283s] [16.491638283s] END
I0320 07:29:51.948183       1 trace.go:219] Trace[79499283]: "iptables ChainExists" (20-Mar-2025 07:29:49.669) (total time: 2084ms):
Trace[79499283]: [2.084566658s] [2.084566658s] END
I0320 07:30:26.911167       1 trace.go:219] Trace[1408126103]: "iptables ChainExists" (20-Mar-2025 07:30:21.714) (total time: 4496ms):
Trace[1408126103]: [4.49696855s] [4.49696855s] END
I0320 07:30:31.025583       1 trace.go:219] Trace[2045355130]: "iptables ChainExists" (20-Mar-2025 07:30:21.604) (total time: 9099ms):
Trace[2045355130]: [9.099460145s] [9.099460145s] END
I0320 07:31:22.812784       1 trace.go:219] Trace[1132835176]: "iptables ChainExists" (20-Mar-2025 07:31:19.515) (total time: 2782ms):
Trace[1132835176]: [2.782027097s] [2.782027097s] END
I0320 07:36:24.205733       1 trace.go:219] Trace[1256927254]: "iptables ChainExists" (20-Mar-2025 07:36:20.020) (total time: 3082ms):
Trace[1256927254]: [3.082351797s] [3.082351797s] END
I0320 07:36:26.502520       1 trace.go:219] Trace[1956903680]: "iptables ChainExists" (20-Mar-2025 07:36:20.515) (total time: 2778ms):
Trace[1956903680]: [2.778612204s] [2.778612204s] END
I0320 07:36:53.199372       1 trace.go:219] Trace[661059522]: "iptables ChainExists" (20-Mar-2025 07:36:49.997) (total time: 2923ms):
Trace[661059522]: [2.923547102s] [2.923547102s] END
I0320 07:36:53.203654       1 trace.go:219] Trace[1273982104]: "iptables ChainExists" (20-Mar-2025 07:36:49.703) (total time: 3296ms):
Trace[1273982104]: [3.296797965s] [3.296797965s] END
I0320 07:37:58.437801       1 trace.go:219] Trace[1095896150]: "iptables ChainExists" (20-Mar-2025 07:37:51.842) (total time: 4503ms):
Trace[1095896150]: [4.503246266s] [4.503246266s] END
I0320 07:37:58.574082       1 trace.go:219] Trace[172905312]: "iptables ChainExists" (20-Mar-2025 07:37:50.061) (total time: 6087ms):
Trace[172905312]: [6.087304215s] [6.087304215s] END
W0320 07:39:21.115130       1 reflector.go:347] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0320 07:39:37.515727       1 reflector.go:347] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0320 07:39:34.515816       1 reflector.go:347] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
I0320 07:39:40.624253       1 trace.go:219] Trace[919069305]: "iptables ChainExists" (20-Mar-2025 07:38:51.283) (total time: 49257ms):
Trace[919069305]: [49.257940615s] [49.257940615s] END
I0320 07:39:41.599129       1 trace.go:219] Trace[313624172]: "iptables ChainExists" (20-Mar-2025 07:38:51.066) (total time: 46179ms):
Trace[313624172]: [46.179602773s] [46.179602773s] END
I0320 07:39:52.362497       1 trace.go:219] Trace[292331325]: "iptables ChainExists" (20-Mar-2025 07:39:49.500) (total time: 2720ms):
Trace[292331325]: [2.720410298s] [2.720410298s] END
I0320 07:39:53.676723       1 trace.go:219] Trace[69994346]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (20-Mar-2025 07:39:41.571) (total time: 12043ms):
Trace[69994346]: ---"Objects listed" error:<nil> 11839ms (07:39:53.361)
Trace[69994346]: [12.043837676s] [12.043837676s] END
I0320 07:39:53.759936       1 trace.go:219] Trace[2074128202]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (20-Mar-2025 07:39:42.716) (total time: 10894ms):
Trace[2074128202]: ---"Objects listed" error:<nil> 10810ms (07:39:53.478)
Trace[2074128202]: [10.894217791s] [10.894217791s] END
I0320 07:39:54.063050       1 trace.go:219] Trace[1236468206]: "iptables ChainExists" (20-Mar-2025 07:39:48.820) (total time: 5291ms):
Trace[1236468206]: [5.291258506s] [5.291258506s] END
I0320 07:39:55.164219       1 trace.go:219] Trace[257374957]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (20-Mar-2025 07:39:22.617) (total time: 32401ms):
Trace[257374957]: ---"Objects listed" error:<nil> 32399ms (07:39:54.967)
Trace[257374957]: [32.401132988s] [32.401132988s] END

* 
* ==> kube-scheduler [30743d0390af] <==
* W0320 07:26:32.321395       1 authentication.go:349] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0320 07:26:32.321406       1 authentication.go:350] Continuing without authentication configuration. This may treat all requests as anonymous.
W0320 07:26:32.321413       1 authentication.go:351] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0320 07:26:32.416809       1 server.go:152] "Starting Kubernetes Scheduler" version="v1.26.3"
I0320 07:26:32.416851       1 server.go:154] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0320 07:26:32.419082       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0320 07:26:32.419456       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0320 07:26:32.419726       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0320 07:26:32.420168       1 shared_informer.go:273] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
W0320 07:26:32.421809       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0320 07:26:32.421841       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0320 07:26:32.421936       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0320 07:26:32.422069       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0320 07:26:32.422195       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0320 07:26:32.422197       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0320 07:26:32.422219       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0320 07:26:32.422222       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0320 07:26:32.423387       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0320 07:26:32.423417       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0320 07:26:32.423697       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0320 07:26:32.423716       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0320 07:26:32.423700       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0320 07:26:32.423743       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0320 07:26:32.423757       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0320 07:26:32.423770       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0320 07:26:32.423866       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0320 07:26:32.423895       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0320 07:26:32.423950       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0320 07:26:32.423973       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0320 07:26:32.424027       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0320 07:26:32.424052       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0320 07:26:32.424065       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0320 07:26:32.424102       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0320 07:26:32.424106       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0320 07:26:32.424132       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0320 07:26:32.424154       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0320 07:26:32.424162       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0320 07:26:32.424194       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0320 07:26:32.424235       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0320 07:26:33.244408       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0320 07:26:33.244466       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0320 07:26:33.268729       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0320 07:26:33.268873       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0320 07:26:33.280134       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0320 07:26:33.280181       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0320 07:26:33.336072       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0320 07:26:33.336145       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0320 07:26:33.342736       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0320 07:26:33.342805       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0320 07:26:33.409768       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0320 07:26:33.409849       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0320 07:26:33.487686       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0320 07:26:33.487722       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0320 07:26:33.534058       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0320 07:26:33.534091       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0320 07:26:33.542559       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0320 07:26:33.542626       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0320 07:26:33.672407       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0320 07:26:33.672473       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
I0320 07:26:35.321094       1 shared_informer.go:280] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* -- Logs begin at Thu 2025-03-20 07:26:11 UTC, end at Thu 2025-03-20 07:43:46 UTC. --
Mar 20 07:38:08 minikube kubelet[2333]: E0320 07:38:08.378477    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:38:21 minikube kubelet[2333]: E0320 07:38:21.557815    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:38:38 minikube kubelet[2333]: I0320 07:38:38.435190    2333 trace.go:219] Trace[1309389788]: "iptables ChainExists" (20-Mar-2025 07:38:35.629) (total time: 2800ms):
Mar 20 07:38:38 minikube kubelet[2333]: Trace[1309389788]: [2.800470736s] [2.800470736s] END
Mar 20 07:38:42 minikube kubelet[2333]: I0320 07:38:42.848303    2333 trace.go:219] Trace[1510277111]: "iptables ChainExists" (20-Mar-2025 07:38:35.629) (total time: 2416ms):
Mar 20 07:38:42 minikube kubelet[2333]: Trace[1510277111]: [2.416178331s] [2.416178331s] END
Mar 20 07:39:07 minikube kubelet[2333]: I0320 07:39:07.056079    2333 trace.go:219] Trace[777265031]: "Calculate volume metrics of kube-api-access-jqpng for pod kube-system/storage-provisioner" (20-Mar-2025 07:39:04.655) (total time: 2297ms):
Mar 20 07:39:07 minikube kubelet[2333]: Trace[777265031]: [2.297094572s] [2.297094572s] END
Mar 20 07:39:54 minikube kubelet[2333]: I0320 07:39:54.670539    2333 trace.go:219] Trace[2118993940]: "Calculate volume metrics of kube-api-access-cnbmm for pod kube-system/coredns-787d4945fb-dq6fr" (20-Mar-2025 07:39:25.606) (total time: 2008ms):
Mar 20 07:39:54 minikube kubelet[2333]: Trace[2118993940]: [2.008048293s] [2.008048293s] END
Mar 20 07:39:56 minikube kubelet[2333]: I0320 07:39:55.564788    2333 trace.go:219] Trace[609370435]: "Calculate volume metrics of etc-ca-certificates for pod kube-system/kube-apiserver-minikube" (20-Mar-2025 07:39:53.078) (total time: 2484ms):
Mar 20 07:39:56 minikube kubelet[2333]: Trace[609370435]: [2.484616476s] [2.484616476s] END
Mar 20 07:39:57 minikube kubelet[2333]: I0320 07:39:57.448844    2333 trace.go:219] Trace[275578984]: "iptables ChainExists" (20-Mar-2025 07:39:48.202) (total time: 9295ms):
Mar 20 07:39:57 minikube kubelet[2333]: Trace[275578984]: [9.295851476s] [9.295851476s] END
Mar 20 07:39:57 minikube kubelet[2333]: I0320 07:39:57.469543    2333 trace.go:219] Trace[1388573168]: "iptables ChainExists" (20-Mar-2025 07:39:38.227) (total time: 18383ms):
Mar 20 07:39:57 minikube kubelet[2333]: Trace[1388573168]: [18.38323969s] [18.38323969s] END
Mar 20 07:39:58 minikube kubelet[2333]: W0320 07:39:58.665735    2333 reflector.go:347] pkg/kubelet/config/apiserver.go:66: watch of *v1.Pod ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
Mar 20 07:39:58 minikube kubelet[2333]: W0320 07:39:58.751877    2333 reflector.go:347] object-"kube-system"/"kube-root-ca.crt": watch of *v1.ConfigMap ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
Mar 20 07:39:58 minikube kubelet[2333]: W0320 07:39:58.755472    2333 reflector.go:347] object-"default"/"kube-root-ca.crt": watch of *v1.ConfigMap ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
Mar 20 07:39:58 minikube kubelet[2333]: W0320 07:39:58.758299    2333 reflector.go:347] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.RuntimeClass ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
Mar 20 07:39:58 minikube kubelet[2333]: W0320 07:39:58.767696    2333 reflector.go:347] object-"kube-system"/"kube-proxy": watch of *v1.ConfigMap ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
Mar 20 07:39:59 minikube kubelet[2333]: W0320 07:39:59.168091    2333 reflector.go:347] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
Mar 20 07:39:59 minikube kubelet[2333]: W0320 07:39:58.848780    2333 reflector.go:347] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.CSIDriver ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
Mar 20 07:39:59 minikube kubelet[2333]: I0320 07:39:58.949279    2333 trace.go:219] Trace[1109921425]: "Calculate volume metrics of log-volume for pod default/combined-service-6745b8c7d-x8qs7" (20-Mar-2025 07:39:55.672) (total time: 3276ms):
Mar 20 07:39:59 minikube kubelet[2333]: Trace[1109921425]: [3.27625711s] [3.27625711s] END
Mar 20 07:40:00 minikube kubelet[2333]: E0320 07:40:00.767881    2333 kubelet.go:2287] "Housekeeping took longer than 15s" err="housekeeping took too long" seconds=93.574654833
Mar 20 07:40:02 minikube kubelet[2333]: E0320 07:40:02.853234    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:40:04 minikube kubelet[2333]: I0320 07:40:04.218401    2333 scope.go:115] "RemoveContainer" containerID="bc4260f5304aa176c5ee076362668c232d50f56b5853066f704348264f775e1a"
Mar 20 07:40:04 minikube kubelet[2333]: I0320 07:40:04.219292    2333 scope.go:115] "RemoveContainer" containerID="a58a1180bc062f2b78e5cb9aa6fc7691ae4626d11e9ee6b8cfddc31ae1ec367a"
Mar 20 07:40:04 minikube kubelet[2333]: E0320 07:40:04.219668    2333 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(39e8638e-d6a7-4c78-ac3e-32f6b14618bd)\"" pod="kube-system/storage-provisioner" podUID=39e8638e-d6a7-4c78-ac3e-32f6b14618bd
Mar 20 07:40:16 minikube kubelet[2333]: I0320 07:40:16.175681    2333 scope.go:115] "RemoveContainer" containerID="bc4260f5304aa176c5ee076362668c232d50f56b5853066f704348264f775e1a"
Mar 20 07:40:16 minikube kubelet[2333]: E0320 07:40:16.175967    2333 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(39e8638e-d6a7-4c78-ac3e-32f6b14618bd)\"" pod="kube-system/storage-provisioner" podUID=39e8638e-d6a7-4c78-ac3e-32f6b14618bd
Mar 20 07:40:22 minikube kubelet[2333]: E0320 07:40:22.355978    2333 remote_image.go:171] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for book-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="book-service:4.0"
Mar 20 07:40:22 minikube kubelet[2333]: E0320 07:40:22.356482    2333 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for book-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="book-service:4.0"
Mar 20 07:40:22 minikube kubelet[2333]: E0320 07:40:22.358110    2333 kuberuntime_manager.go:872] container &Container{Name:book-service,Image:book-service:4.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:8080,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:log-volume,ReadOnly:false,MountPath:/logs,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-l85t8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod combined-service-6745b8c7d-x8qs7_default(3783f1af-7cbd-4bab-9454-70a8aa0f2964): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: pull access denied for book-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Mar 20 07:40:26 minikube kubelet[2333]: E0320 07:40:26.383080    2333 remote_image.go:171] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for sidecar-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="sidecar-service:4.0"
Mar 20 07:40:26 minikube kubelet[2333]: E0320 07:40:26.383153    2333 kuberuntime_image.go:53] "Failed to pull image" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for sidecar-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="sidecar-service:4.0"
Mar 20 07:40:26 minikube kubelet[2333]: E0320 07:40:26.383276    2333 kuberuntime_manager.go:872] container &Container{Name:sidecar-service,Image:sidecar-service:4.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:8081,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:log-volume,ReadOnly:false,MountPath:/logs,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-l85t8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod combined-service-6745b8c7d-x8qs7_default(3783f1af-7cbd-4bab-9454-70a8aa0f2964): ErrImagePull: rpc error: code = Unknown desc = Error response from daemon: pull access denied for sidecar-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Mar 20 07:40:26 minikube kubelet[2333]: E0320 07:40:26.383348    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: pull access denied for book-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\", failed to \"StartContainer\" for \"sidecar-service\" with ErrImagePull: \"rpc error: code = Unknown desc = Error response from daemon: pull access denied for sidecar-service, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:40:27 minikube kubelet[2333]: I0320 07:40:27.150848    2333 scope.go:115] "RemoveContainer" containerID="bc4260f5304aa176c5ee076362668c232d50f56b5853066f704348264f775e1a"
Mar 20 07:40:27 minikube kubelet[2333]: E0320 07:40:27.151041    2333 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(39e8638e-d6a7-4c78-ac3e-32f6b14618bd)\"" pod="kube-system/storage-provisioner" podUID=39e8638e-d6a7-4c78-ac3e-32f6b14618bd
Mar 20 07:40:38 minikube kubelet[2333]: I0320 07:40:38.150012    2333 scope.go:115] "RemoveContainer" containerID="bc4260f5304aa176c5ee076362668c232d50f56b5853066f704348264f775e1a"
Mar 20 07:40:38 minikube kubelet[2333]: E0320 07:40:38.150217    2333 pod_workers.go:965] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 40s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(39e8638e-d6a7-4c78-ac3e-32f6b14618bd)\"" pod="kube-system/storage-provisioner" podUID=39e8638e-d6a7-4c78-ac3e-32f6b14618bd
Mar 20 07:40:40 minikube kubelet[2333]: E0320 07:40:40.157552    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:40:52 minikube kubelet[2333]: I0320 07:40:52.139985    2333 scope.go:115] "RemoveContainer" containerID="bc4260f5304aa176c5ee076362668c232d50f56b5853066f704348264f775e1a"
Mar 20 07:40:54 minikube kubelet[2333]: E0320 07:40:54.144835    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:41:07 minikube kubelet[2333]: E0320 07:41:07.147893    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:41:21 minikube kubelet[2333]: E0320 07:41:21.138768    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:41:35 minikube kubelet[2333]: W0320 07:41:35.306963    2333 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Mar 20 07:41:36 minikube kubelet[2333]: E0320 07:41:36.139767    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:41:47 minikube kubelet[2333]: E0320 07:41:47.141152    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:41:58 minikube kubelet[2333]: E0320 07:41:58.150624    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:42:09 minikube kubelet[2333]: E0320 07:42:09.134522    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:42:20 minikube kubelet[2333]: E0320 07:42:20.128489    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:42:31 minikube kubelet[2333]: E0320 07:42:31.132276    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:42:44 minikube kubelet[2333]: E0320 07:42:44.129336    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:42:58 minikube kubelet[2333]: E0320 07:42:58.124938    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:43:09 minikube kubelet[2333]: E0320 07:43:09.123939    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:43:22 minikube kubelet[2333]: E0320 07:43:22.120665    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964
Mar 20 07:43:33 minikube kubelet[2333]: E0320 07:43:33.127005    2333 pod_workers.go:965] "Error syncing pod, skipping" err="[failed to \"StartContainer\" for \"book-service\" with ImagePullBackOff: \"Back-off pulling image \\\"book-service:4.0\\\"\", failed to \"StartContainer\" for \"sidecar-service\" with ImagePullBackOff: \"Back-off pulling image \\\"sidecar-service:4.0\\\"\"]" pod="default/combined-service-6745b8c7d-x8qs7" podUID=3783f1af-7cbd-4bab-9454-70a8aa0f2964

* 
* ==> storage-provisioner [41028b0f7f94] <==
* I0320 07:40:53.052039       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0320 07:40:53.162980       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0320 07:40:53.164633       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0320 07:41:10.626126       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0320 07:41:10.627323       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_ab687566-0cc5-422f-8893-5603e13c154e!
I0320 07:41:10.627314       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"4f3e8ec6-c224-4e20-82cd-7e164af741f3", APIVersion:"v1", ResourceVersion:"984", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_ab687566-0cc5-422f-8893-5603e13c154e became leader
I0320 07:41:10.729888       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_ab687566-0cc5-422f-8893-5603e13c154e!

* 
* ==> storage-provisioner [bc4260f5304a] <==
* k8s.io/apimachinery/pkg/runtime/serializer/streaming.(*decoder).Decode(0xc00011fbd0, 0x0, 0x18bc168, 0xc0005d4d80, 0x0, 0x0, 0x461dc0, 0xc0001c33e0, 0xc000593e50)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/runtime/serializer/streaming/streaming.go:77 +0x89
k8s.io/client-go/rest/watch.(*Decoder).Decode(0xc0005442c0, 0xc000593ef0, 0x8, 0x18baa20, 0xc000464280, 0x0, 0x0)
	/Users/medya/go/pkg/mod/k8s.io/client-go@v0.20.5/rest/watch/decoder.go:49 +0x6e
k8s.io/apimachinery/pkg/watch.(*StreamWatcher).receive(0xc0000b9240)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:104 +0x14a
created by k8s.io/apimachinery/pkg/watch.NewStreamWatcher
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:71 +0xbe

goroutine 548 [sync.Cond.Wait]:
sync.runtime_notifyListWait(0xc0003749e0, 0x1)
	/usr/local/go/src/runtime/sema.go:513 +0xf8
sync.(*Cond).Wait(0xc0003749d0)
	/usr/local/go/src/sync/cond.go:56 +0x99
golang.org/x/net/http2.(*pipe).Read(0xc0003749c8, 0xc000472001, 0x5ff, 0x5ff, 0x0, 0x0, 0x0)
	/Users/medya/go/pkg/mod/golang.org/x/net@v0.0.0-20201224014010-6772e930b67b/http2/pipe.go:65 +0x97
golang.org/x/net/http2.transportResponseBody.Read(0xc0003749a0, 0xc000472001, 0x5ff, 0x5ff, 0x0, 0x0, 0x0)
	/Users/medya/go/pkg/mod/golang.org/x/net@v0.0.0-20201224014010-6772e930b67b/http2/transport.go:2108 +0xaf
encoding/json.(*Decoder).refill(0xc00043f4a0, 0xa, 0x9)
	/usr/local/go/src/encoding/json/stream.go:165 +0xeb
encoding/json.(*Decoder).readValue(0xc00043f4a0, 0x0, 0x0, 0x152aee0)
	/usr/local/go/src/encoding/json/stream.go:140 +0x1ff
encoding/json.(*Decoder).Decode(0xc00043f4a0, 0x154a160, 0xc00055ad80, 0x203000, 0x203000)
	/usr/local/go/src/encoding/json/stream.go:63 +0x7c
k8s.io/apimachinery/pkg/util/framer.(*jsonFrameReader).Read(0xc00057bd10, 0xc000446800, 0x400, 0x400, 0x40, 0x38, 0x15b0440)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/util/framer/framer.go:152 +0x1a8
k8s.io/apimachinery/pkg/runtime/serializer/streaming.(*decoder).Decode(0xc00018c690, 0x0, 0x18bc168, 0xc0002b3040, 0x0, 0x0, 0x461dc0, 0xc0001c3d40, 0xc0005ede50)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/runtime/serializer/streaming/streaming.go:77 +0x89
k8s.io/client-go/rest/watch.(*Decoder).Decode(0xc000544740, 0xc0005edef0, 0x8, 0x18baa48, 0xc0005d0380, 0x0, 0x0)
	/Users/medya/go/pkg/mod/k8s.io/client-go@v0.20.5/rest/watch/decoder.go:49 +0x6e
k8s.io/apimachinery/pkg/watch.(*StreamWatcher).receive(0xc0000b9e80)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:104 +0x14a
created by k8s.io/apimachinery/pkg/watch.NewStreamWatcher
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:71 +0xbe

goroutine 563 [sync.Cond.Wait]:
sync.runtime_notifyListWait(0xc000582300, 0x1)
	/usr/local/go/src/runtime/sema.go:513 +0xf8
sync.(*Cond).Wait(0xc0005822f0)
	/usr/local/go/src/sync/cond.go:56 +0x99
golang.org/x/net/http2.(*pipe).Read(0xc0005822e8, 0xc0001ce001, 0x5ff, 0x5ff, 0x0, 0x0, 0x0)
	/Users/medya/go/pkg/mod/golang.org/x/net@v0.0.0-20201224014010-6772e930b67b/http2/pipe.go:65 +0x97
golang.org/x/net/http2.transportResponseBody.Read(0xc0005822c0, 0xc0001ce001, 0x5ff, 0x5ff, 0x0, 0x0, 0x0)
	/Users/medya/go/pkg/mod/golang.org/x/net@v0.0.0-20201224014010-6772e930b67b/http2/transport.go:2108 +0xaf
encoding/json.(*Decoder).refill(0xc000582580, 0xa, 0x9)
	/usr/local/go/src/encoding/json/stream.go:165 +0xeb
encoding/json.(*Decoder).readValue(0xc000582580, 0x0, 0x0, 0x152aee0)
	/usr/local/go/src/encoding/json/stream.go:140 +0x1ff
encoding/json.(*Decoder).Decode(0xc000582580, 0x154a160, 0xc0005e4f78, 0x203000, 0x203000)
	/usr/local/go/src/encoding/json/stream.go:63 +0x7c
k8s.io/apimachinery/pkg/util/framer.(*jsonFrameReader).Read(0xc00029bf50, 0xc0003ae400, 0x400, 0x400, 0x40, 0x38, 0x15b0440)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/util/framer/framer.go:152 +0x1a8
k8s.io/apimachinery/pkg/runtime/serializer/streaming.(*decoder).Decode(0xc0005b6730, 0x0, 0x18bc168, 0xc0001b4fc0, 0x0, 0x0, 0x461dc0, 0xc000658ba0, 0xc000071e50)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/runtime/serializer/streaming/streaming.go:77 +0x89
k8s.io/client-go/rest/watch.(*Decoder).Decode(0xc0001b2c20, 0xc000071ef0, 0x8, 0x18bbba0, 0xc000083800, 0x0, 0x0)
	/Users/medya/go/pkg/mod/k8s.io/client-go@v0.20.5/rest/watch/decoder.go:49 +0x6e
k8s.io/apimachinery/pkg/watch.(*StreamWatcher).receive(0xc0005d4540)
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:104 +0x14a
created by k8s.io/apimachinery/pkg/watch.NewStreamWatcher
	/Users/medya/go/pkg/mod/k8s.io/apimachinery@v0.20.5/pkg/watch/streamwatcher.go:71 +0xbe

